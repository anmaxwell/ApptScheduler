{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from tensorboardX import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulerEnv(gym.Env):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        #starting parameters\n",
    "        num_gps = 10\n",
    "        num_slots = 15\n",
    "        num_pre_booked = 75\n",
    "        to_book = [4,2,3,1]\n",
    "        num_to_book = len(to_book)\n",
    "        agent_pos = [0,0]\n",
    "        reward_decay = 0.95\n",
    "        \n",
    "        #set parameters for the day\n",
    "        self.num_gps = num_gps\n",
    "        self.num_slots = num_slots\n",
    "        self.num_pre_booked = num_pre_booked\n",
    "        self.to_book = to_book\n",
    "        self.num_to_book = num_to_book\n",
    "        self.diary_slots = num_gps*num_slots\n",
    "        self.agent_pos = agent_pos\n",
    "        self.reward_decay = reward_decay\n",
    "\n",
    "        #set action space to move around the grid\n",
    "        self.action_space = gym.spaces.Discrete(4) #up, down, left, right\n",
    "        \n",
    "        #set observation space \n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(self.num_slots, self.num_gps), dtype=np.int32)\n",
    "   \n",
    "    #creates daily diary for each gp, randomly populates prebooked appointments and resets parameters\n",
    "    def reset(self):\n",
    "\n",
    "        #creates zero filled dataframe with row per time slot and column per gp\n",
    "        self.state = np.zeros((self.num_slots, self.num_gps),dtype=float)\n",
    "\n",
    "        #randomly enters a 1 for each pre booked appointments\n",
    "        pre_booked = self.num_pre_booked\n",
    "        while pre_booked>0:\n",
    "            pre_booked -= 1\n",
    "            self.state[np.random.randint(self.num_slots), np.random.randint(self.num_gps)] = 1\n",
    "            \n",
    "        #randomly sets the agent start space\n",
    "        self.agent_pos = [np.random.randint(self.num_slots), np.random.randint(self.num_gps)]\n",
    "\n",
    "        #resets parameters for new episode\n",
    "        self.done = False\n",
    "        self.reward = 0\n",
    "        self.appt_idx = 0\n",
    "        self.decay_steps = 1\n",
    "        \n",
    "        print('starting state', self.state.sum(), self.state)\n",
    "\n",
    "        return self.state\n",
    "    \n",
    "    #calculates new position of the agent based on the action\n",
    "    def move_agent(self, action):\n",
    "\n",
    "        #set boundaries for the grid\n",
    "        max_row = env.num_slots - 1\n",
    "        max_col = env.num_gps - 1\n",
    "\n",
    "        #set new co-ordinates for the agent\n",
    "        new_row = self.agent_pos[0]\n",
    "        new_col = self.agent_pos[1]\n",
    "\n",
    "        #calculate what the new position may be based on the action without going out the griid\n",
    "        if action == 0:\n",
    "            print('up')\n",
    "            new_row = max(self.agent_pos[0] - 1, 0)\n",
    "        if action == 1:\n",
    "            print('down')\n",
    "            new_row = min(self.agent_pos[0] + 1, max_row)\n",
    "        if action == 2:\n",
    "            print('left')\n",
    "            new_col = max(self.agent_pos[1] - 1, 0)\n",
    "        if action == 3:\n",
    "            print('right')\n",
    "            new_col = min(self.agent_pos[1] + 1, max_col)\n",
    "\n",
    "        new_pos = [new_row, new_col]\n",
    "        print('new pos', new_pos)\n",
    "\n",
    "        return new_pos\n",
    "\n",
    "    #checks if we can look to book appointment starting here\n",
    "    def check_bookable(self):\n",
    "        return self.state[self.agent_pos[0], self.agent_pos[1]] == 0.0\n",
    "    \n",
    "    #checks if the appointment fits\n",
    "    def check_and_book(self):\n",
    "        max_row = env.num_slots - 1\n",
    "\n",
    "        #checks if the appointment fits\n",
    "        cells_to_check = self.to_book[self.appt_idx]\n",
    "        if cells_to_check==1:\n",
    "            print('good to check for single')\n",
    "            if self.state[self.agent_pos[0], self.agent_pos[1]] == 0:\n",
    "                self.state[self.agent_pos[0], self.agent_pos[1]] = 1\n",
    "                self.appt_idx += 1\n",
    "                self.decay_steps = 1\n",
    "            else:\n",
    "                print('already taken')\n",
    "                self.decay_steps += 1\n",
    "        if cells_to_check==2:\n",
    "            #check we're not at the bottom of the grid\n",
    "            if self.agent_pos[0]<max_row:\n",
    "                #check the next cells is also 0.0\n",
    "                print('good to check for double')\n",
    "                if self.state[self.agent_pos[0], self.agent_pos[1]] == 0 and \\\n",
    "                self.state[(self.agent_pos[0]+1), self.agent_pos[1]] == 0:\n",
    "                    self.state[self.agent_pos[0], self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+1), self.agent_pos[1]] = 1\n",
    "                    self.appt_idx += 1\n",
    "                    print('go ahead and book')\n",
    "                    self.decay_steps = 1\n",
    "                else:\n",
    "                    print('already taken')\n",
    "                    self.decay_steps += 1\n",
    "            else:\n",
    "                print('not for double')\n",
    "                self.decay_steps += 1\n",
    "        if cells_to_check==3:\n",
    "            #check we're not at the bottom of the grid\n",
    "            if self.agent_pos[0]+1<max_row:\n",
    "                print('good to check for treble')\n",
    "                if self.state[self.agent_pos[0], self.agent_pos[1]] == 0 and \\\n",
    "                self.state[(self.agent_pos[0]+1), self.agent_pos[1]] == 0 \\\n",
    "                 and self.state[(self.agent_pos[0]+2), self.agent_pos[1]] == 0:\n",
    "                    self.state[self.agent_pos[0], self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+1), self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+2), self.agent_pos[1]] = 1\n",
    "                    self.appt_idx += 1\n",
    "                    print('go ahead and book')\n",
    "                    self.decay_steps = 1\n",
    "                else:\n",
    "                    print('already taken')\n",
    "                    self.decay_steps += 1\n",
    "            else:\n",
    "                print('not for treble')\n",
    "                self.decay_steps += 1\n",
    "        if cells_to_check==4:\n",
    "            #check we're not at the bottom of the grid\n",
    "            if self.agent_pos[0]+2<max_row:\n",
    "                #check the next cells is also 0.0\n",
    "                print('good for quad')\n",
    "                if self.state[self.agent_pos[0], self.agent_pos[1]] == 0 and \\\n",
    "                self.state[(self.agent_pos[0]+1), self.agent_pos[1]] == 0 \\\n",
    "                 and self.state[(self.agent_pos[0]+2), self.agent_pos[1]] == 0 and \\\n",
    "                self.state[(self.agent_pos[0]+3), self.agent_pos[1]] == 0:\n",
    "                    self.state[self.agent_pos[0], self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+1), self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+2), self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+3), self.agent_pos[1]] = 1\n",
    "                    self.appt_idx += 1\n",
    "                    print('go ahead and book')\n",
    "                    self.decay_steps = 1\n",
    "                else:\n",
    "                    print('already taken')\n",
    "                    self.decay_steps += 1\n",
    "            else:\n",
    "                print('not for quad')\n",
    "                self.decay_steps += 1\n",
    "\n",
    "        next_state = self.state\n",
    "\n",
    "        return next_state\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        print('start step' , self.decay_steps)\n",
    "        #get new positioin of agent based on action\n",
    "        self.agent_pos = self.move_agent(action)\n",
    "        print('trying to book', self.to_book, self.appt_idx)\n",
    "        \n",
    "        #check if it's possible to book then book\n",
    "        if self.check_bookable():\n",
    "            self.state = self.check_and_book()\n",
    "            print('checked here')\n",
    "        else:\n",
    "            print('not bookable')\n",
    "            self.decay_steps += 1\n",
    "        \n",
    "        #work out if episode complete\n",
    "        if self.appt_idx == len(self.to_book):\n",
    "            print('all booked')\n",
    "            self.done = True\n",
    "            \n",
    "        #work out rewards\n",
    "        self.reward = self.reward_decay**self.decay_steps\n",
    "        \n",
    "        print('step', self.decay_steps)\n",
    "        print('end step')\n",
    "\n",
    "        info = {}\n",
    "\n",
    "        return self.state, self.reward, self.done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, action_size):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128) \n",
    "        )\n",
    "\n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, action_size)\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        init_out = self.net(x)\n",
    "        return self.actor(init_out), self.critic(init_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert numpy array to tensor for input\n",
    "def tensor_convert(x):\n",
    "    return torch.from_numpy(x).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise environment, model and optimiser\n",
    "env = SchedulerEnv()\n",
    "model = Model((env.diary_slots), env.action_space.n)\n",
    "\n",
    "#optimizer = torch.optim.Adam(model.parameters(), lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, \n",
    "#                             amsgrad=False)\n",
    "#optimizer.zero_grad()\n",
    "\n",
    "writer = SummaryWriter()\n",
    "\n",
    "state = env.reset()\n",
    "print('start pos', env.agent_pos)\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "\n",
    "    #create model input from flattened grid\n",
    "    nn_input = torch.flatten(tensor_convert(state))\n",
    "    actor, critic = model(nn_input)\n",
    "    \n",
    "    print('get new action')\n",
    "    #action = torch.argmax(actor)\n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    #print(F.softmax(actor), action)\n",
    "\n",
    "    #run through step to book appointment\n",
    "    new_state, reward, done, info = env.step(action)\n",
    "    state = new_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(env.state.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.appt_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
