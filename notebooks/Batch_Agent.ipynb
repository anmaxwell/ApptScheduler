{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/ale_py/roms/utils.py:90: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
      "  for external in metadata.entry_points().get(self.group, []):\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import ptan\n",
    "import numpy as np\n",
    "import argparse\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.utils as nn_utils\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "gamma = 0.99\n",
    "batch_size = 11\n",
    "num_envs = 6\n",
    "reward_steps = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_shape, n_actions):\n",
    "        super(Model, self).__init__()\n",
    "\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_shape[0]*input_shape[1], 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128) \n",
    "        )\n",
    "        \n",
    "        self.actor = nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, n_actions)\n",
    "        )\n",
    "\n",
    "        self.critic = nn.Sequential(\n",
    "            nn.Linear(128, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # flatten the observation space Box to linear tensor\n",
    "        x_flat = torch.flatten(x, 1,2).to(torch.float32)\n",
    "        #print('x_flat', x_flat.size(), x_flat)\n",
    "        init_out = self.net(x_flat)\n",
    "        return self.actor(init_out), self.critic(init_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unpack_batch(batch, model, device='cpu'):\n",
    "\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "    not_done_idx = []\n",
    "    last_states = []\n",
    "    #create lists of the states, actions and rewards\n",
    "    for idx, exp in enumerate(batch):\n",
    "        states.append(np.array(exp.state, copy=False))\n",
    "        actions.append(int(exp.action))\n",
    "        rewards.append(exp.reward)\n",
    "        #separate out the last states to be able to calculate the rewards\n",
    "        if exp.last_state is not None:\n",
    "            not_done_idx.append(idx)\n",
    "            last_states.append(np.array(exp.last_state, copy=False))\n",
    "\n",
    "    #convert to tensors for calculations\n",
    "    states = torch.FloatTensor(\n",
    "        np.array(states, copy=False)).to(device)\n",
    "    actions = torch.LongTensor(actions).to(device)\n",
    "\n",
    "    # handle rewards\n",
    "    rewards_np = np.array(rewards, dtype=np.float32)\n",
    "    if not_done_idx:\n",
    "        last_states = torch.FloatTensor(np.array(last_states, copy=False)).to(device)\n",
    "        last_vals = model(last_states)[1]\n",
    "        last_vals_np = last_vals.data.cpu().numpy()[:, 0]\n",
    "        last_vals_np *= gamma ** reward_steps\n",
    "        rewards_np[not_done_idx] += last_vals_np\n",
    "\n",
    "    rewards = torch.FloatTensor(rewards_np).to(device)\n",
    "\n",
    "    return states, actions, rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SchedulerEnv(gym.Env):\n",
    "\n",
    "    def __init__(self):\n",
    "        \n",
    "        #starting parameters\n",
    "        num_gps = 100\n",
    "        num_slots = 32\n",
    "        num_pre_booked = 15\n",
    "        to_book = [2,1,2,2,1,1,1]\n",
    "        num_to_book = len(to_book)\n",
    "        agent_pos = [0,0]\n",
    "        reward_decay = 0.95\n",
    "        \n",
    "        #set parameters for the day\n",
    "        self.num_gps = num_gps\n",
    "        self.num_slots = num_slots\n",
    "        self.num_pre_booked = num_pre_booked\n",
    "        self.to_book = to_book\n",
    "        self.num_to_book = num_to_book\n",
    "        self.diary_slots = num_gps*num_slots\n",
    "        self.agent_pos = agent_pos\n",
    "        self.reward_decay = reward_decay\n",
    "\n",
    "        #set action space to move around the grid\n",
    "        self.action_space = gym.spaces.Discrete(4) #up, down, left, right\n",
    "        \n",
    "        #set observation space \n",
    "        self.observation_space = gym.spaces.Box(low=0, high=1, shape=(self.num_slots, self.num_gps), dtype=np.int32)\n",
    "   \n",
    "    #creates daily diary for each gp, randomly populates prebooked appointments and resets parameters\n",
    "    def reset(self):\n",
    "\n",
    "        #creates zero filled dataframe with row per time slot and column per gp\n",
    "        self.state = np.zeros((self.num_slots, self.num_gps),dtype=float)\n",
    "\n",
    "        #randomly enters a 1 for each pre booked appointments\n",
    "        pre_booked = self.num_pre_booked\n",
    "        while pre_booked>0:\n",
    "            pre_booked -= 1\n",
    "            self.state[np.random.randint(self.num_slots), np.random.randint(self.num_gps)] = 1\n",
    "            \n",
    "        #randomly sets the agent start space\n",
    "        self.agent_pos = [np.random.randint(self.num_slots), np.random.randint(self.num_gps)]\n",
    "\n",
    "        #resets parameters for new episode\n",
    "        self.done = False\n",
    "        self.reward = 0\n",
    "        self.appt_idx = 0\n",
    "        self.decay_steps = 1\n",
    "        \n",
    "        #print('starting state', self.state.sum(), self.state)\n",
    "\n",
    "        return self.state\n",
    "    \n",
    "    #calculates new position of the agent based on the action\n",
    "    def move_agent(self, action):\n",
    "\n",
    "        #set boundaries for the grid\n",
    "        max_row = self.num_slots - 1\n",
    "        max_col = self.num_gps - 1\n",
    "\n",
    "        #setting new co-ordinates for the agent\n",
    "        new_row = self.agent_pos[0]\n",
    "        new_col = self.agent_pos[1]\n",
    "\n",
    "        #calculate what the new position may be based on the action without going out the grid\n",
    "        if action == 0:\n",
    "            #print('up')\n",
    "            new_row = max(self.agent_pos[0] - 1, 0)\n",
    "        if action == 1:\n",
    "            #print('down')\n",
    "            new_row = min(self.agent_pos[0] + 1, max_row)\n",
    "        if action == 2:\n",
    "            #print('left')\n",
    "            new_col = max(self.agent_pos[1] - 1, 0)\n",
    "        if action == 3:\n",
    "            #print('right')\n",
    "            new_col = min(self.agent_pos[1] + 1, max_col)\n",
    "\n",
    "        new_pos = [new_row, new_col]\n",
    "        #print('new pos', new_pos)\n",
    "\n",
    "        return new_pos\n",
    "\n",
    "    #checks if we can look to book appointment starting here\n",
    "    def check_bookable(self):\n",
    "        return self.state[self.agent_pos[0], self.agent_pos[1]] == 0.0\n",
    "    \n",
    "    #action if we can't book the appointment\n",
    "    def invalid_booking(self):\n",
    "        #print('cant book')\n",
    "        self.decay_steps += 1\n",
    "        self.reward = -1\n",
    "        \n",
    "    #action if we can book the appointment\n",
    "    def valid_booking(self):\n",
    "        #print('go ahead and book')\n",
    "        self.appt_idx += 1\n",
    "        self.decay_steps = 1\n",
    "        self.reward = 1\n",
    "    \n",
    "    #checks if the appointment fits\n",
    "    def check_and_book(self):\n",
    "        \n",
    "        max_row = self.num_slots - 1\n",
    "        cells_to_check = self.to_book[self.appt_idx]\n",
    "        \n",
    "        if cells_to_check==1:\n",
    "            #print('good to check for single')\n",
    "            if self.state[self.agent_pos[0], self.agent_pos[1]] == 0:\n",
    "                self.state[self.agent_pos[0], self.agent_pos[1]] = 1\n",
    "                self.valid_booking()\n",
    "            else:\n",
    "                #print('single taken')\n",
    "                self.invalid_booking()\n",
    "\n",
    "        if cells_to_check==2:\n",
    "            #check we're not at the bottom of the grid\n",
    "            if self.agent_pos[0]<max_row:\n",
    "                #check the next cells is also 0.0\n",
    "                #print('good to check for double')\n",
    "                if self.state[self.agent_pos[0], self.agent_pos[1]] == 0 and \\\n",
    "                self.state[(self.agent_pos[0]+1), self.agent_pos[1]] == 0:\n",
    "                    self.state[self.agent_pos[0], self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+1), self.agent_pos[1]] = 1\n",
    "                    self.valid_booking()\n",
    "                    self.agent_pos = [(self.agent_pos[0]+1), self.agent_pos[1]]\n",
    "                    #print('after booking', self.agent_pos)\n",
    "                else:\n",
    "                    #print('double taken')\n",
    "                    self.invalid_booking()\n",
    "            else:\n",
    "                #print('not for double')\n",
    "                self.invalid_booking()\n",
    "                \n",
    "        if cells_to_check==3:\n",
    "            #check we're not at the bottom of the grid\n",
    "            if self.agent_pos[0]+1<max_row:\n",
    "                #print('good to check for treble')\n",
    "                if self.state[self.agent_pos[0], self.agent_pos[1]] == 0 and \\\n",
    "                self.state[(self.agent_pos[0]+1), self.agent_pos[1]] == 0 \\\n",
    "                 and self.state[(self.agent_pos[0]+2), self.agent_pos[1]] == 0:\n",
    "                    self.state[self.agent_pos[0], self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+1), self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+2), self.agent_pos[1]] = 1\n",
    "                    self.valid_booking()\n",
    "                    self.agent_pos = [(self.agent_pos[0]+2), self.agent_pos[1]]\n",
    "                else:\n",
    "                    #print('treble taken')\n",
    "                    self.invalid_booking()\n",
    "            else:\n",
    "                #print('not for treble')\n",
    "                self.invalid_booking()\n",
    "                \n",
    "        if cells_to_check==4:\n",
    "            #check we're not at the bottom of the grid\n",
    "            if self.agent_pos[0]+2<max_row:\n",
    "                #check the next cells is also 0.0\n",
    "                #print('good for quad')\n",
    "                if self.state[self.agent_pos[0], self.agent_pos[1]] == 0 and \\\n",
    "                self.state[(self.agent_pos[0]+1), self.agent_pos[1]] == 0 \\\n",
    "                 and self.state[(self.agent_pos[0]+2), self.agent_pos[1]] == 0 and \\\n",
    "                self.state[(self.agent_pos[0]+3), self.agent_pos[1]] == 0:\n",
    "                    self.state[self.agent_pos[0], self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+1), self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+2), self.agent_pos[1]] = 1\n",
    "                    self.state[(self.agent_pos[0]+3), self.agent_pos[1]] = 1\n",
    "                    self.valid_booking()\n",
    "                    self.agent_pos = [(self.agent_pos[0]+3), self.agent_pos[1]]\n",
    "                else:\n",
    "                    #print('quad taken')\n",
    "                    self.invalid_booking()\n",
    "            else:\n",
    "                #print('not for quad')\n",
    "                self.invalid_booking()\n",
    "\n",
    "        next_state = self.state\n",
    "\n",
    "        return next_state\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        #print('start step' , self.decay_steps)\n",
    "        #get new position of agent based on action\n",
    "        new_agent_pos = self.move_agent(action)\n",
    "        #print('new and old pos', new_agent_pos, self.agent_pos)\n",
    "        \n",
    "        #if the agent is stuck on an edge then move to a new position\n",
    "        if new_agent_pos == self.agent_pos:\n",
    "            self.agent_pos = [np.random.randint(self.num_slots), np.random.randint(self.num_gps)]\n",
    "            #print('here1', self.agent_pos)\n",
    "        else:\n",
    "            self.agent_pos = new_agent_pos\n",
    "            #print('here2', self.agent_pos)\n",
    "        \n",
    "        #print('trying to book', self.to_book, self.appt_idx)\n",
    "        \n",
    "        #check if it's possible to book then book\n",
    "        if self.check_bookable():\n",
    "            #print('checked here')\n",
    "            self.state = self.check_and_book()\n",
    "        else:\n",
    "            #print('not bookable')\n",
    "            self.invalid_booking()\n",
    "        \n",
    "        #work out if episode complete\n",
    "        if self.appt_idx == len(self.to_book):\n",
    "            #print('all booked')\n",
    "            self.done = True\n",
    "  \n",
    "        #work out rewards\n",
    "        #self.reward = (1 - (self.reward_decay**self.decay_steps))\n",
    "        \n",
    "        #print('step', self.decay_steps, self.reward)\n",
    "        #print('end step')\n",
    "\n",
    "        info = {}\n",
    "        return self.state, self.reward, self.done, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 0.7927932790480554 step 120\n",
      "ave_batch_loss 3.3803622245788576 step 120\n",
      "ave_batch_reward 1.3872011817163892 step 230\n",
      "ave_batch_loss 4.314593394597371 step 230\n",
      "ave_batch_reward 1.8789456619156732 step 340\n",
      "ave_batch_loss 5.333387633164723 step 340\n",
      "ave_batch_reward 2.8976784812079535 step 450\n",
      "ave_batch_loss 4.413786225848728 step 450\n",
      "ave_batch_reward 4.293225871192084 step 560\n",
      "ave_batch_loss 7.188605255550808 step 560\n",
      "ave_batch_reward 4.762633138232761 step 670\n",
      "ave_batch_loss 10.464578628540039 step 670\n",
      "ave_batch_reward 4.35230376985338 step 780\n",
      "ave_batch_loss 7.136023786332872 step 780\n",
      "ave_batch_reward 4.16373085975647 step 890\n",
      "ave_batch_loss 7.5537782775031195 step 890\n",
      "ave_batch_reward 4.729552931255764 step 1000\n",
      "ave_batch_loss 9.058580981360542 step 1000\n",
      "ave_batch_reward 4.9304408232371015 step 1110\n",
      "ave_batch_loss 10.592374695671928 step 1110\n",
      "ave_batch_reward 4.828351126776801 step 1220\n",
      "ave_batch_loss 9.110197226206461 step 1220\n",
      "ave_batch_reward 4.797639634874132 step 1330\n",
      "ave_batch_loss 9.165490044487846 step 1330\n",
      "ave_batch_reward 4.939067999521892 step 1440\n",
      "ave_batch_loss 9.815638224283854 step 1440\n",
      "ave_batch_reward 4.9520261022779675 step 1550\n",
      "ave_batch_loss 9.615571816762289 step 1550\n",
      "ave_batch_reward 5.108227544360691 step 1660\n",
      "ave_batch_loss 11.040185610453287 step 1660\n",
      "ave_batch_reward 5.375799338022868 step 1770\n",
      "ave_batch_loss 10.55471240149604 step 1770\n",
      "ave_batch_reward 5.0899551709493 step 1880\n",
      "ave_batch_loss 10.516430960761177 step 1880\n",
      "ave_batch_reward 5.298696358998616 step 1990\n",
      "ave_batch_loss 10.71906312306722 step 1990\n",
      "ave_batch_reward 5.125139342414008 step 2100\n",
      "ave_batch_loss 10.10066721174452 step 2100\n",
      "ave_batch_reward 5.0912649101681176 step 2210\n",
      "ave_batch_loss 10.575590027703178 step 2210\n",
      "ave_batch_reward 5.384464793735081 step 2320\n",
      "ave_batch_loss 10.463817490471733 step 2320\n",
      "ave_batch_reward 5.010344664255778 step 2430\n",
      "ave_batch_loss 9.653878847757975 step 2430\n",
      "ave_batch_reward 5.47642535633511 step 2540\n",
      "ave_batch_loss 10.259320153130425 step 2540\n",
      "ave_batch_reward 5.398277627097236 step 2650\n",
      "ave_batch_loss 10.920104026794434 step 2650\n",
      "ave_batch_reward 5.1959102683597145 step 2760\n",
      "ave_batch_loss 9.725991619957817 step 2760\n",
      "ave_batch_reward 5.12112643983629 step 2870\n",
      "ave_batch_loss 10.032988018459744 step 2870\n",
      "ave_batch_reward 5.167494508955214 step 2980\n",
      "ave_batch_loss 11.018589125739204 step 2980\n",
      "ave_batch_reward 5.360210763083564 step 3090\n",
      "ave_batch_loss 11.020445399814182 step 3090\n",
      "ave_batch_reward 5.168800009621514 step 3200\n",
      "ave_batch_loss 11.000599755181206 step 3200\n",
      "ave_batch_reward 5.238590664333767 step 3310\n",
      "ave_batch_loss 10.665685123867458 step 3310\n",
      "ave_batch_reward 5.200682216220432 step 3420\n",
      "ave_batch_loss 11.03790283203125 step 3420\n",
      "ave_batch_reward 5.056816313001844 step 3530\n",
      "ave_batch_loss 10.475385453965929 step 3530\n",
      "ave_batch_reward 4.996439245012072 step 3640\n",
      "ave_batch_loss 9.323669804467094 step 3640\n",
      "ave_batch_reward 5.129461023542616 step 3750\n",
      "ave_batch_loss 9.680308553907606 step 3750\n",
      "ave_batch_reward 5.03572596444024 step 3860\n",
      "ave_batch_loss 9.327736854553223 step 3860\n",
      "ave_batch_reward 5.355193667941624 step 3970\n",
      "ave_batch_loss 10.541012658013237 step 3970\n",
      "ave_batch_reward 4.816015746858385 step 4080\n",
      "ave_batch_loss 10.91340324613783 step 4080\n",
      "ave_batch_reward 4.887620846430461 step 4190\n",
      "ave_batch_loss 8.916849666171604 step 4190\n",
      "ave_batch_reward 5.275435235765245 step 4300\n",
      "ave_batch_loss 10.741579267713758 step 4300\n",
      "ave_batch_reward 5.259681330786811 step 4410\n",
      "ave_batch_loss 10.68656783633762 step 4410\n",
      "ave_batch_reward 5.03476169374254 step 4520\n",
      "ave_batch_loss 10.556696467929417 step 4520\n",
      "ave_batch_reward 5.233008199267918 step 4630\n",
      "ave_batch_loss 10.534370846218533 step 4630\n",
      "ave_batch_reward 5.112364451090495 step 4740\n",
      "ave_batch_loss 10.884724617004395 step 4740\n",
      "ave_batch_reward 5.401589658525255 step 4850\n",
      "ave_batch_loss 10.411591423882378 step 4850\n",
      "ave_batch_reward 5.173000388675266 step 4960\n",
      "ave_batch_loss 11.081785096062553 step 4960\n",
      "ave_batch_reward 5.228969838884142 step 5070\n",
      "ave_batch_loss 10.799415058559841 step 5070\n",
      "ave_batch_reward 5.144949489169651 step 5180\n",
      "ave_batch_loss 10.198649565378824 step 5180\n",
      "ave_batch_reward 5.0954263475206165 step 5290\n",
      "ave_batch_loss 9.671304119957817 step 5290\n",
      "ave_batch_reward 5.255216015709771 step 5400\n",
      "ave_batch_loss 10.653073204888237 step 5400\n",
      "ave_batch_reward 5.207619693544176 step 5510\n",
      "ave_batch_loss 11.302064153883192 step 5510\n",
      "ave_batch_reward 5.249995125664605 step 5620\n",
      "ave_batch_loss 10.406371964348686 step 5620\n",
      "ave_batch_reward 5.211814641952515 step 5730\n",
      "ave_batch_loss 9.47899087270101 step 5730\n",
      "ave_batch_reward 5.202214982774523 step 5840\n",
      "ave_batch_loss 9.671208063761393 step 5840\n",
      "ave_batch_reward 5.060587830013699 step 5950\n",
      "ave_batch_loss 9.219283739725748 step 5950\n",
      "ave_batch_reward 5.195554786258274 step 6060\n",
      "ave_batch_loss 9.953528298272026 step 6060\n",
      "ave_batch_reward 5.112077289157444 step 6170\n",
      "ave_batch_loss 9.877179993523491 step 6170\n",
      "ave_batch_reward 5.272771570417616 step 6280\n",
      "ave_batch_loss 10.71486070421007 step 6280\n",
      "ave_batch_reward 5.259901523590088 step 6390\n",
      "ave_batch_loss 10.855558077494303 step 6390\n",
      "ave_batch_reward 4.954753663804796 step 6500\n",
      "ave_batch_loss 9.845578299628365 step 6500\n",
      "ave_batch_reward 5.264832390679254 step 6610\n",
      "ave_batch_loss 10.46428214179145 step 6610\n",
      "ave_batch_reward 5.0648423830668134 step 6720\n",
      "ave_batch_loss 9.555825657314724 step 6720\n",
      "ave_batch_reward 5.179561588499281 step 6830\n",
      "ave_batch_loss 9.097735722859701 step 6830\n",
      "ave_batch_reward 5.091033167309231 step 6940\n",
      "ave_batch_loss 9.657786793178982 step 6940\n",
      "ave_batch_reward 5.318278471628825 step 7050\n",
      "ave_batch_loss 10.418966929117838 step 7050\n",
      "ave_batch_reward 5.120288530985515 step 7160\n",
      "ave_batch_loss 10.798447608947754 step 7160\n",
      "ave_batch_reward 5.337826702329847 step 7270\n",
      "ave_batch_loss 9.219761477576363 step 7270\n",
      "ave_batch_reward 4.991326623492771 step 7380\n",
      "ave_batch_loss 9.726833979288736 step 7380\n",
      "ave_batch_reward 5.442529201507568 step 7490\n",
      "ave_batch_loss 9.887073622809517 step 7490\n",
      "ave_batch_reward 5.124094274308947 step 7600\n",
      "ave_batch_loss 10.565903663635254 step 7600\n",
      "ave_batch_reward 5.359490712483724 step 7710\n",
      "ave_batch_loss 10.953191439310709 step 7710\n",
      "ave_batch_reward 4.94646692276001 step 7820\n",
      "ave_batch_loss 9.034814728630913 step 7820\n",
      "ave_batch_reward 5.1484874619377985 step 7930\n",
      "ave_batch_loss 9.349428706698948 step 7930\n",
      "ave_batch_reward 5.0129894150627985 step 8040\n",
      "ave_batch_loss 10.471655739678276 step 8040\n",
      "ave_batch_reward 5.072335057788425 step 8150\n",
      "ave_batch_loss 9.648931079440647 step 8150\n",
      "ave_batch_reward 5.180926852756077 step 8260\n",
      "ave_batch_loss 10.34969515270657 step 8260\n",
      "ave_batch_reward 5.363698164621989 step 8370\n",
      "ave_batch_loss 10.198008219401041 step 8370\n",
      "ave_batch_reward 5.203657627105713 step 8480\n",
      "ave_batch_loss 10.520131429036459 step 8480\n",
      "ave_batch_reward 5.093382464514838 step 8590\n",
      "ave_batch_loss 10.649779319763184 step 8590\n",
      "ave_batch_reward 4.980428165859646 step 8700\n",
      "ave_batch_loss 9.27037779490153 step 8700\n",
      "ave_batch_reward 5.113179895612928 step 8810\n",
      "ave_batch_loss 9.61856116188897 step 8810\n",
      "ave_batch_reward 5.044634607103136 step 8920\n",
      "ave_batch_loss 9.612956258985731 step 8920\n",
      "ave_batch_reward 5.38127252790663 step 9030\n",
      "ave_batch_loss 9.921744505564371 step 9030\n",
      "ave_batch_reward 5.210998959011501 step 9140\n",
      "ave_batch_loss 10.19528145260281 step 9140\n",
      "ave_batch_reward 4.927230755488078 step 9250\n",
      "ave_batch_loss 9.305440372890896 step 9250\n",
      "ave_batch_reward 5.077114078733656 step 9360\n",
      "ave_batch_loss 9.986437850528294 step 9360\n",
      "ave_batch_reward 4.998006184895833 step 9470\n",
      "ave_batch_loss 10.500369601779514 step 9470\n",
      "ave_batch_reward 5.208159287770589 step 9580\n",
      "ave_batch_loss 9.917926258511013 step 9580\n",
      "ave_batch_reward 5.1727279557122126 step 9690\n",
      "ave_batch_loss 9.903739187452528 step 9690\n",
      "ave_batch_reward 5.324456426832411 step 9800\n",
      "ave_batch_loss 10.796689457363552 step 9800\n",
      "ave_batch_reward 5.165789021386041 step 9910\n",
      "ave_batch_loss 9.452977498372396 step 9910\n",
      "ave_batch_reward 5.200599829355876 step 10020\n",
      "ave_batch_loss 10.47298961215549 step 10020\n",
      "ave_batch_reward 5.121428595648871 step 10130\n",
      "ave_batch_loss 10.760990460713705 step 10130\n",
      "ave_batch_reward 5.163763788011339 step 10240\n",
      "ave_batch_loss 10.69271183013916 step 10240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 5.031325552198622 step 10350\n",
      "ave_batch_loss 10.770365715026855 step 10350\n",
      "ave_batch_reward 5.227910306718615 step 10460\n",
      "ave_batch_loss 10.902318742540148 step 10460\n",
      "ave_batch_reward 5.092733383178711 step 10570\n",
      "ave_batch_loss 10.113860236273872 step 10570\n",
      "ave_batch_reward 5.130991988711887 step 10680\n",
      "ave_batch_loss 10.076834360758463 step 10680\n",
      "ave_batch_reward 5.240369743771023 step 10790\n",
      "ave_batch_loss 9.878457652197945 step 10790\n",
      "ave_batch_reward 5.169296317630344 step 10900\n",
      "ave_batch_loss 10.745310889350044 step 10900\n",
      "ave_batch_reward 5.276642534467909 step 11010\n",
      "ave_batch_loss 10.382305992974175 step 11010\n",
      "ave_batch_reward 4.976211123996311 step 11120\n",
      "ave_batch_loss 9.901999261644152 step 11120\n",
      "ave_batch_reward 5.2561508019765215 step 11230\n",
      "ave_batch_loss 9.319781409369575 step 11230\n",
      "ave_batch_reward 5.11783848868476 step 11340\n",
      "ave_batch_loss 9.054891374376085 step 11340\n",
      "ave_batch_reward 5.137901306152344 step 11450\n",
      "ave_batch_loss 9.625856717427572 step 11450\n",
      "ave_batch_reward 5.1667717297871905 step 11560\n",
      "ave_batch_loss 10.73789013756646 step 11560\n",
      "ave_batch_reward 5.249416351318359 step 11670\n",
      "ave_batch_loss 11.331551127963596 step 11670\n",
      "ave_batch_reward 5.0282976097530785 step 11780\n",
      "ave_batch_loss 10.911420610215929 step 11780\n",
      "ave_batch_reward 5.123800171746148 step 11890\n",
      "ave_batch_loss 9.913650512695312 step 11890\n",
      "ave_batch_reward 5.313635349273682 step 12000\n",
      "ave_batch_loss 10.560790909661186 step 12000\n",
      "ave_batch_reward 4.934964444902208 step 12110\n",
      "ave_batch_loss 9.27874787648519 step 12110\n",
      "ave_batch_reward 5.026348908742269 step 12220\n",
      "ave_batch_loss 9.567223972744411 step 12220\n",
      "ave_batch_reward 4.996098730299208 step 12330\n",
      "ave_batch_loss 8.48510291841295 step 12330\n",
      "ave_batch_reward 4.982280890146892 step 12440\n",
      "ave_batch_loss 9.791498290167915 step 12440\n",
      "ave_batch_reward 5.115182293785943 step 12550\n",
      "ave_batch_loss 10.009621090359158 step 12550\n",
      "ave_batch_reward 5.124443425072564 step 12660\n",
      "ave_batch_loss 9.703865263197157 step 12660\n",
      "ave_batch_reward 5.148658646477593 step 12770\n",
      "ave_batch_loss 10.647618505689833 step 12770\n",
      "ave_batch_reward 5.279066801071167 step 12880\n",
      "ave_batch_loss 10.509607050153944 step 12880\n",
      "ave_batch_reward 5.109002749125163 step 12990\n",
      "ave_batch_loss 10.490583737691244 step 12990\n",
      "ave_batch_reward 5.331869761149089 step 13100\n",
      "ave_batch_loss 10.670830726623535 step 13100\n",
      "ave_batch_reward 5.188336319393581 step 13210\n",
      "ave_batch_loss 10.426771375868055 step 13210\n",
      "ave_batch_reward 5.1195262802971735 step 13320\n",
      "ave_batch_loss 10.864137437608507 step 13320\n",
      "ave_batch_reward 5.108669757843018 step 13430\n",
      "ave_batch_loss 10.077630784776476 step 13430\n",
      "ave_batch_reward 5.176406410005358 step 13540\n",
      "ave_batch_loss 10.589190906948513 step 13540\n",
      "ave_batch_reward 5.076397630903456 step 13650\n",
      "ave_batch_loss 10.653006447686089 step 13650\n",
      "ave_batch_reward 5.0275391472710504 step 13760\n",
      "ave_batch_loss 9.494263860914442 step 13760\n",
      "ave_batch_reward 5.086228264702691 step 13870\n",
      "ave_batch_loss 9.114756849077013 step 13870\n",
      "ave_batch_reward 5.186828136444092 step 13980\n",
      "ave_batch_loss 9.29625744289822 step 13980\n",
      "ave_batch_reward 5.193922890557183 step 14090\n",
      "ave_batch_loss 10.38470893436008 step 14090\n",
      "ave_batch_reward 5.378557205200195 step 14200\n",
      "ave_batch_loss 10.517379548814562 step 14200\n",
      "ave_batch_reward 5.175172593858507 step 14310\n",
      "ave_batch_loss 10.62493864695231 step 14310\n",
      "ave_batch_reward 5.164003954993354 step 14420\n",
      "ave_batch_loss 10.132922172546387 step 14420\n",
      "ave_batch_reward 5.109256903330485 step 14530\n",
      "ave_batch_loss 10.097105662027994 step 14530\n",
      "ave_batch_reward 5.133417818281385 step 14640\n",
      "ave_batch_loss 10.111402617560493 step 14640\n",
      "ave_batch_reward 5.120607905917698 step 14750\n",
      "ave_batch_loss 9.803547806209988 step 14750\n",
      "ave_batch_reward 5.144218497806126 step 14860\n",
      "ave_batch_loss 10.401461177402073 step 14860\n",
      "ave_batch_reward 4.8549003336164684 step 14970\n",
      "ave_batch_loss 9.894731786515978 step 14970\n",
      "ave_batch_reward 4.977745638953315 step 15080\n",
      "ave_batch_loss 9.543795903523764 step 15080\n",
      "ave_batch_reward 5.094337039523655 step 15190\n",
      "ave_batch_loss 9.846515390608046 step 15190\n",
      "ave_batch_reward 5.00345426135593 step 15300\n",
      "ave_batch_loss 10.458950678507486 step 15300\n",
      "ave_batch_reward 5.413912137349446 step 15410\n",
      "ave_batch_loss 10.84921137491862 step 15410\n",
      "ave_batch_reward 5.149149047003852 step 15520\n",
      "ave_batch_loss 10.629317177666557 step 15520\n",
      "ave_batch_reward 4.9072953595055475 step 15630\n",
      "ave_batch_loss 9.238463348812527 step 15630\n",
      "ave_batch_reward 4.963174237145318 step 15740\n",
      "ave_batch_loss 9.236319859822592 step 15740\n",
      "ave_batch_reward 5.2152659098307295 step 15850\n",
      "ave_batch_loss 9.491898854573568 step 15850\n",
      "ave_batch_reward 4.984114699893528 step 15960\n",
      "ave_batch_loss 9.136008421579996 step 15960\n",
      "ave_batch_reward 5.2058108117845325 step 16070\n",
      "ave_batch_loss 9.678745057847765 step 16070\n",
      "ave_batch_reward 5.143685711754693 step 16180\n",
      "ave_batch_loss 10.540793736775717 step 16180\n",
      "ave_batch_reward 5.236367464065552 step 16290\n",
      "ave_batch_loss 9.832800123426649 step 16290\n",
      "ave_batch_reward 5.091602007548015 step 16400\n",
      "ave_batch_loss 10.41565884484185 step 16400\n",
      "ave_batch_reward 5.21698440445794 step 16510\n",
      "ave_batch_loss 10.735903210110134 step 16510\n",
      "ave_batch_reward 5.066172944174872 step 16620\n",
      "ave_batch_loss 10.19393973880344 step 16620\n",
      "ave_batch_reward 5.347950643963284 step 16730\n",
      "ave_batch_loss 10.4885958565606 step 16730\n",
      "ave_batch_reward 5.221371968587239 step 16840\n",
      "ave_batch_loss 10.80653190612793 step 16840\n",
      "ave_batch_reward 5.211017608642578 step 16950\n",
      "ave_batch_loss 10.599458588494194 step 16950\n",
      "ave_batch_reward 5.1676596535576715 step 17060\n",
      "ave_batch_loss 10.517107751634386 step 17060\n",
      "ave_batch_reward 4.97265871365865 step 17170\n",
      "ave_batch_loss 9.248053232828775 step 17170\n",
      "ave_batch_reward 5.000719441307916 step 17280\n",
      "ave_batch_loss 8.960488478342691 step 17280\n",
      "ave_batch_reward 5.105066908730401 step 17390\n",
      "ave_batch_loss 8.986690256330702 step 17390\n",
      "ave_batch_reward 5.031491703457302 step 17500\n",
      "ave_batch_loss 8.806533972422281 step 17500\n",
      "ave_batch_reward 5.159015046225654 step 17610\n",
      "ave_batch_loss 9.639969984690348 step 17610\n",
      "ave_batch_reward 5.1520430776807995 step 17720\n",
      "ave_batch_loss 10.316323598225912 step 17720\n",
      "ave_batch_reward 5.1363402472601996 step 17830\n",
      "ave_batch_loss 10.071815914577908 step 17830\n",
      "ave_batch_reward 5.2103442615932885 step 17940\n",
      "ave_batch_loss 10.13822470770942 step 17940\n",
      "ave_batch_reward 4.997815503014459 step 18050\n",
      "ave_batch_loss 9.439516279432508 step 18050\n",
      "ave_batch_reward 5.411353588104248 step 18160\n",
      "ave_batch_loss 9.877326753404406 step 18160\n",
      "ave_batch_reward 5.163031260172526 step 18270\n",
      "ave_batch_loss 10.759726948208279 step 18270\n",
      "ave_batch_reward 5.17433049943712 step 18380\n",
      "ave_batch_loss 10.401645024617514 step 18380\n",
      "ave_batch_reward 5.133009592692058 step 18490\n",
      "ave_batch_loss 10.659018092685276 step 18490\n",
      "ave_batch_reward 5.156230979495579 step 18600\n",
      "ave_batch_loss 10.076360384623209 step 18600\n",
      "ave_batch_reward 5.291637659072876 step 18710\n",
      "ave_batch_loss 10.651330206129286 step 18710\n",
      "ave_batch_reward 5.203363047705756 step 18820\n",
      "ave_batch_loss 10.58116012149387 step 18820\n",
      "ave_batch_reward 5.343422359890408 step 18930\n",
      "ave_batch_loss 10.167325231764051 step 18930\n",
      "ave_batch_reward 5.149333900875515 step 19040\n",
      "ave_batch_loss 10.077367146809896 step 19040\n",
      "ave_batch_reward 5.267778979407416 step 19150\n",
      "ave_batch_loss 10.121900929345024 step 19150\n",
      "ave_batch_reward 5.0832265218098955 step 19260\n",
      "ave_batch_loss 9.561971028645834 step 19260\n",
      "ave_batch_reward 5.147864765591091 step 19370\n",
      "ave_batch_loss 10.158177799648708 step 19370\n",
      "ave_batch_reward 5.3474662568834095 step 19480\n",
      "ave_batch_loss 11.006657706366646 step 19480\n",
      "ave_batch_reward 5.3392050001356335 step 19590\n",
      "ave_batch_loss 10.581116676330566 step 19590\n",
      "ave_batch_reward 5.205711205800374 step 19700\n",
      "ave_batch_loss 11.025590790642632 step 19700\n",
      "ave_batch_reward 5.162286546495226 step 19810\n",
      "ave_batch_loss 10.01611720191108 step 19810\n",
      "ave_batch_reward 5.138702604505751 step 19920\n",
      "ave_batch_loss 9.9627808464898 step 19920\n",
      "ave_batch_reward 5.214094003041585 step 20030\n",
      "ave_batch_loss 9.966191291809082 step 20030\n",
      "ave_batch_reward 5.177108605702718 step 20140\n",
      "ave_batch_loss 10.51722526550293 step 20140\n",
      "ave_batch_reward 5.0726668039957685 step 20250\n",
      "ave_batch_loss 10.179996066623264 step 20250\n",
      "ave_batch_reward 5.396058162053426 step 20360\n",
      "ave_batch_loss 10.988007969326443 step 20360\n",
      "ave_batch_reward 4.99009018474155 step 20470\n",
      "ave_batch_loss 10.498988363477919 step 20470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 5.312419043646918 step 20580\n",
      "ave_batch_loss 10.758958286709255 step 20580\n",
      "ave_batch_reward 5.252944469451904 step 20690\n",
      "ave_batch_loss 9.460780620574951 step 20690\n",
      "ave_batch_reward 5.11913447909885 step 20800\n",
      "ave_batch_loss 10.78576374053955 step 20800\n",
      "ave_batch_reward 5.182332356770833 step 20910\n",
      "ave_batch_loss 9.54203626844618 step 20910\n",
      "ave_batch_reward 5.087407535976833 step 21020\n",
      "ave_batch_loss 9.84144073062473 step 21020\n",
      "ave_batch_reward 5.104547712537977 step 21130\n",
      "ave_batch_loss 9.27966441048516 step 21130\n",
      "ave_batch_reward 4.99278810289171 step 21240\n",
      "ave_batch_loss 10.818244722154406 step 21240\n",
      "ave_batch_reward 5.164246188269721 step 21350\n",
      "ave_batch_loss 10.306227684020996 step 21350\n",
      "ave_batch_reward 5.269475248124865 step 21460\n",
      "ave_batch_loss 10.070697943369547 step 21460\n",
      "ave_batch_reward 5.311410744984944 step 21570\n",
      "ave_batch_loss 10.658455106947157 step 21570\n",
      "ave_batch_reward 5.2812844382392035 step 21680\n",
      "ave_batch_loss 10.474566565619575 step 21680\n",
      "ave_batch_reward 5.221540133158366 step 21790\n",
      "ave_batch_loss 10.6200319925944 step 21790\n",
      "ave_batch_reward 5.19637656211853 step 21900\n",
      "ave_batch_loss 9.999058935377333 step 21900\n",
      "ave_batch_reward 5.166675329208374 step 22010\n",
      "ave_batch_loss 10.170284536149767 step 22010\n",
      "ave_batch_reward 5.238833056555854 step 22120\n",
      "ave_batch_loss 10.799956427680122 step 22120\n",
      "ave_batch_reward 5.055817815992567 step 22230\n",
      "ave_batch_loss 10.278247833251953 step 22230\n",
      "ave_batch_reward 5.240562015109592 step 22340\n",
      "ave_batch_loss 10.308790153927273 step 22340\n",
      "ave_batch_reward 5.1383969518873425 step 22450\n",
      "ave_batch_loss 10.401007652282715 step 22450\n",
      "ave_batch_reward 5.239942815568712 step 22560\n",
      "ave_batch_loss 9.81012233098348 step 22560\n",
      "ave_batch_reward 5.108020623524983 step 22670\n",
      "ave_batch_loss 9.944304042392307 step 22670\n",
      "ave_batch_reward 5.170514133241442 step 22780\n",
      "ave_batch_loss 10.317067994011772 step 22780\n",
      "ave_batch_reward 5.298937479654948 step 22890\n",
      "ave_batch_loss 10.759508980645073 step 22890\n",
      "ave_batch_reward 5.209854920705159 step 23000\n",
      "ave_batch_loss 10.378831757439507 step 23000\n",
      "ave_batch_reward 4.8382643063863116 step 23110\n",
      "ave_batch_loss 9.502750290764702 step 23110\n",
      "ave_batch_reward 5.361874898274739 step 23220\n",
      "ave_batch_loss 10.591579543219673 step 23220\n",
      "ave_batch_reward 5.220044718848334 step 23330\n",
      "ave_batch_loss 10.749037000868055 step 23330\n",
      "ave_batch_reward 5.247612953186035 step 23440\n",
      "ave_batch_loss 10.91934151119656 step 23440\n",
      "ave_batch_reward 5.088199747933282 step 23550\n",
      "ave_batch_loss 10.034055603875053 step 23550\n",
      "ave_batch_reward 5.187597062852648 step 23660\n",
      "ave_batch_loss 10.42789978451199 step 23660\n",
      "ave_batch_reward 5.143573178185357 step 23770\n",
      "ave_batch_loss 10.008600129021538 step 23770\n",
      "ave_batch_reward 5.0416065322028265 step 23880\n",
      "ave_batch_loss 9.353369606865776 step 23880\n",
      "ave_batch_reward 5.422486066818237 step 23990\n",
      "ave_batch_loss 10.509970559014214 step 23990\n",
      "ave_batch_reward 5.20150974061754 step 24100\n",
      "ave_batch_loss 10.499641312493218 step 24100\n",
      "ave_batch_reward 5.427076869540745 step 24210\n",
      "ave_batch_loss 10.68146832784017 step 24210\n",
      "ave_batch_reward 5.055399974187215 step 24320\n",
      "ave_batch_loss 10.401785426669651 step 24320\n",
      "ave_batch_reward 5.3934789763556585 step 24430\n",
      "ave_batch_loss 9.914374457465279 step 24430\n",
      "ave_batch_reward 5.0297250217861595 step 24540\n",
      "ave_batch_loss 10.07361290189955 step 24540\n",
      "ave_batch_reward 5.090513997607761 step 24650\n",
      "ave_batch_loss 9.789600001441109 step 24650\n",
      "ave_batch_reward 5.173105398813884 step 24760\n",
      "ave_batch_loss 10.523969438340929 step 24760\n",
      "ave_batch_reward 5.203519450293647 step 24870\n",
      "ave_batch_loss 9.781480683220757 step 24870\n",
      "ave_batch_reward 5.130543046527439 step 24980\n",
      "ave_batch_loss 10.23709774017334 step 24980\n",
      "ave_batch_reward 5.186250103844537 step 25090\n",
      "ave_batch_loss 11.164739502800835 step 25090\n",
      "ave_batch_reward 5.160025967491998 step 25200\n",
      "ave_batch_loss 10.692611270480686 step 25200\n",
      "ave_batch_reward 5.2098827891879615 step 25310\n",
      "ave_batch_loss 9.748897234598795 step 25310\n",
      "ave_batch_reward 5.156327406565349 step 25420\n",
      "ave_batch_loss 10.188585493299696 step 25420\n",
      "ave_batch_reward 5.210600429111057 step 25530\n",
      "ave_batch_loss 10.58320787217882 step 25530\n",
      "ave_batch_reward 5.180211120181614 step 25640\n",
      "ave_batch_loss 10.627355151706272 step 25640\n",
      "ave_batch_reward 5.042925251854791 step 25750\n",
      "ave_batch_loss 10.835920227898491 step 25750\n",
      "ave_batch_reward 5.38648968272739 step 25860\n",
      "ave_batch_loss 10.749499003092447 step 25860\n",
      "ave_batch_reward 5.098605632781982 step 25970\n",
      "ave_batch_loss 10.644425180223253 step 25970\n",
      "ave_batch_reward 5.334082709418403 step 26080\n",
      "ave_batch_loss 10.29478152592977 step 26080\n",
      "ave_batch_reward 5.033480008443196 step 26190\n",
      "ave_batch_loss 10.412849532233345 step 26190\n",
      "ave_batch_reward 5.282841020160252 step 26300\n",
      "ave_batch_loss 10.36050017674764 step 26300\n",
      "ave_batch_reward 5.151985433366564 step 26410\n",
      "ave_batch_loss 9.978628158569336 step 26410\n",
      "ave_batch_reward 5.305609544118245 step 26520\n",
      "ave_batch_loss 9.862339867485893 step 26520\n",
      "ave_batch_reward 5.080404731962416 step 26630\n",
      "ave_batch_loss 9.824863698747423 step 26630\n",
      "ave_batch_reward 5.088113307952881 step 26740\n",
      "ave_batch_loss 9.17584859000312 step 26740\n",
      "ave_batch_reward 5.109136846330431 step 26850\n",
      "ave_batch_loss 10.523220909966362 step 26850\n",
      "ave_batch_reward 5.183285342322455 step 26960\n",
      "ave_batch_loss 10.179071691301134 step 26960\n",
      "ave_batch_reward 5.216340992185804 step 27070\n",
      "ave_batch_loss 10.651013586256239 step 27070\n",
      "ave_batch_reward 5.230311499701606 step 27180\n",
      "ave_batch_loss 10.738154093424479 step 27180\n",
      "ave_batch_reward 5.149886926015218 step 27290\n",
      "ave_batch_loss 10.295384301079643 step 27290\n",
      "ave_batch_reward 4.974517822265625 step 27400\n",
      "ave_batch_loss 10.177772098117405 step 27400\n",
      "ave_batch_reward 5.278002818425496 step 27510\n",
      "ave_batch_loss 10.063963466220432 step 27510\n",
      "ave_batch_reward 5.086157692803277 step 27620\n",
      "ave_batch_loss 9.916091177198622 step 27620\n",
      "ave_batch_reward 5.17615532875061 step 27730\n",
      "ave_batch_loss 10.381234486897787 step 27730\n",
      "ave_batch_reward 5.213809013366699 step 27840\n",
      "ave_batch_loss 10.565619892544216 step 27840\n",
      "ave_batch_reward 5.293579737345378 step 27950\n",
      "ave_batch_loss 10.563892470465767 step 27950\n",
      "ave_batch_reward 5.255314111709595 step 28060\n",
      "ave_batch_loss 10.856842464870876 step 28060\n",
      "ave_batch_reward 5.240011162228054 step 28170\n",
      "ave_batch_loss 10.810138490464952 step 28170\n",
      "ave_batch_reward 5.10184383392334 step 28280\n",
      "ave_batch_loss 10.20698070526123 step 28280\n",
      "ave_batch_reward 5.317813131544325 step 28390\n",
      "ave_batch_loss 10.76398754119873 step 28390\n",
      "ave_batch_reward 5.0551778475443525 step 28500\n",
      "ave_batch_loss 9.335444026523167 step 28500\n",
      "ave_batch_reward 5.173496458265516 step 28610\n",
      "ave_batch_loss 10.76147429148356 step 28610\n",
      "ave_batch_reward 5.133564101325141 step 28720\n",
      "ave_batch_loss 10.138099564446343 step 28720\n",
      "ave_batch_reward 5.125646670659383 step 28830\n",
      "ave_batch_loss 9.84289460712009 step 28830\n",
      "ave_batch_reward 5.185251394907634 step 28940\n",
      "ave_batch_loss 10.404076735178629 step 28940\n",
      "ave_batch_reward 5.172743744320339 step 29050\n",
      "ave_batch_loss 10.848434236314562 step 29050\n",
      "ave_batch_reward 5.348581790924072 step 29160\n",
      "ave_batch_loss 10.501838048299154 step 29160\n",
      "ave_batch_reward 5.172031243642171 step 29270\n",
      "ave_batch_loss 10.22441185845269 step 29270\n",
      "ave_batch_reward 5.335583315955268 step 29380\n",
      "ave_batch_loss 10.024789492289225 step 29380\n",
      "ave_batch_reward 5.253645658493042 step 29490\n",
      "ave_batch_loss 10.802390840318468 step 29490\n",
      "ave_batch_reward 5.1069578594631615 step 29600\n",
      "ave_batch_loss 10.4636197619968 step 29600\n",
      "ave_batch_reward 5.1672288576761884 step 29710\n",
      "ave_batch_loss 9.61188374625312 step 29710\n",
      "ave_batch_reward 5.067722267574734 step 29820\n",
      "ave_batch_loss 9.713958475324842 step 29820\n",
      "ave_batch_reward 4.760627428690593 step 29930\n",
      "ave_batch_loss 10.598063204023573 step 29930\n",
      "ave_batch_reward 4.9558638201819525 step 30040\n",
      "ave_batch_loss 9.550997734069824 step 30040\n",
      "ave_batch_reward 5.05048484272427 step 30150\n",
      "ave_batch_loss 9.585571765899658 step 30150\n",
      "ave_batch_reward 5.216793855031331 step 30260\n",
      "ave_batch_loss 10.830653508504232 step 30260\n",
      "ave_batch_reward 5.301766077677409 step 30370\n",
      "ave_batch_loss 11.146782769097221 step 30370\n",
      "ave_batch_reward 5.089017974005805 step 30480\n",
      "ave_batch_loss 10.810890091790093 step 30480\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 5.355544567108154 step 30590\n",
      "ave_batch_loss 10.236200650533041 step 30590\n",
      "ave_batch_reward 5.264405303531223 step 30700\n",
      "ave_batch_loss 10.496074358622232 step 30700\n",
      "ave_batch_reward 5.083683013916016 step 30810\n",
      "ave_batch_loss 9.901006274753147 step 30810\n",
      "ave_batch_reward 5.073610226313273 step 30920\n",
      "ave_batch_loss 10.464320288764107 step 30920\n",
      "ave_batch_reward 5.463833332061768 step 31030\n",
      "ave_batch_loss 11.491325166490343 step 31030\n",
      "ave_batch_reward 5.124676465988159 step 31140\n",
      "ave_batch_loss 10.957761340671116 step 31140\n",
      "ave_batch_reward 5.23734548356798 step 31250\n",
      "ave_batch_loss 9.907944467332628 step 31250\n",
      "ave_batch_reward 5.129859103096856 step 31360\n",
      "ave_batch_loss 9.8459259668986 step 31360\n",
      "ave_batch_reward 5.216495831807454 step 31470\n",
      "ave_batch_loss 10.501654518975151 step 31470\n",
      "ave_batch_reward 5.092924859788683 step 31580\n",
      "ave_batch_loss 10.322150389353434 step 31580\n",
      "ave_batch_reward 5.288170178731282 step 31690\n",
      "ave_batch_loss 10.827070660061306 step 31690\n",
      "ave_batch_reward 5.1884786287943525 step 31800\n",
      "ave_batch_loss 11.17838880750868 step 31800\n",
      "ave_batch_reward 5.198292785220676 step 31910\n",
      "ave_batch_loss 10.633523835076225 step 31910\n",
      "ave_batch_reward 5.279660224914551 step 32020\n",
      "ave_batch_loss 10.947374873691135 step 32020\n",
      "ave_batch_reward 5.099907133314344 step 32130\n",
      "ave_batch_loss 10.0791654586792 step 32130\n",
      "ave_batch_reward 5.397067493862576 step 32240\n",
      "ave_batch_loss 10.74579906463623 step 32240\n",
      "ave_batch_reward 5.182568762037489 step 32350\n",
      "ave_batch_loss 10.82711050245497 step 32350\n",
      "ave_batch_reward 5.291921933492024 step 32460\n",
      "ave_batch_loss 10.505072275797525 step 32460\n",
      "ave_batch_reward 5.014588461981879 step 32570\n",
      "ave_batch_loss 9.894181569417318 step 32570\n",
      "ave_batch_reward 5.136220667097303 step 32680\n",
      "ave_batch_loss 10.0041151576572 step 32680\n",
      "ave_batch_reward 5.017855962117513 step 32790\n",
      "ave_batch_loss 10.503237088521322 step 32790\n",
      "ave_batch_reward 5.13306819068061 step 32900\n",
      "ave_batch_loss 11.04424614376492 step 32900\n",
      "ave_batch_reward 5.5074585808648004 step 33010\n",
      "ave_batch_loss 11.039262135823568 step 33010\n",
      "ave_batch_reward 5.094627963172065 step 33120\n",
      "ave_batch_loss 9.64823129442003 step 33120\n",
      "ave_batch_reward 5.249222914377849 step 33230\n",
      "ave_batch_loss 9.945477061801487 step 33230\n",
      "ave_batch_reward 5.206151909298367 step 33340\n",
      "ave_batch_loss 10.529471503363716 step 33340\n",
      "ave_batch_reward 5.291758802202013 step 33450\n",
      "ave_batch_loss 10.76613966623942 step 33450\n",
      "ave_batch_reward 5.347160127427843 step 33560\n",
      "ave_batch_loss 11.700230810377333 step 33560\n",
      "ave_batch_reward 5.175072299109565 step 33670\n",
      "ave_batch_loss 10.838603443569607 step 33670\n",
      "ave_batch_reward 5.17648802863227 step 33780\n",
      "ave_batch_loss 10.184740808275011 step 33780\n",
      "ave_batch_reward 5.309445937474568 step 33890\n",
      "ave_batch_loss 10.086569415198433 step 33890\n",
      "ave_batch_reward 5.198307196299235 step 34000\n",
      "ave_batch_loss 9.50794776280721 step 34000\n",
      "ave_batch_reward 5.129565609825982 step 34110\n",
      "ave_batch_loss 9.470598644680447 step 34110\n",
      "ave_batch_reward 5.229805522494846 step 34220\n",
      "ave_batch_loss 10.594379531012642 step 34220\n",
      "ave_batch_reward 5.210903273688422 step 34330\n",
      "ave_batch_loss 10.343249003092447 step 34330\n",
      "ave_batch_reward 5.4210631052653 step 34440\n",
      "ave_batch_loss 11.25918992360433 step 34440\n",
      "ave_batch_reward 5.141162739859687 step 34550\n",
      "ave_batch_loss 10.013799773322212 step 34550\n",
      "ave_batch_reward 5.255897204081218 step 34660\n",
      "ave_batch_loss 10.11817349327935 step 34660\n",
      "ave_batch_reward 5.106511010064019 step 34770\n",
      "ave_batch_loss 10.234040472242567 step 34770\n",
      "ave_batch_reward 5.421484602822198 step 34880\n",
      "ave_batch_loss 11.157858954535591 step 34880\n",
      "ave_batch_reward 5.016030973858303 step 34990\n",
      "ave_batch_loss 12.241105609469944 step 34990\n",
      "ave_batch_reward 4.872531705432468 step 35100\n",
      "ave_batch_loss 9.174229621887207 step 35100\n",
      "ave_batch_reward 5.248284233940972 step 35210\n",
      "ave_batch_loss 9.749955230289036 step 35210\n",
      "ave_batch_reward 4.974465847015381 step 35320\n",
      "ave_batch_loss 9.581312603420681 step 35320\n",
      "ave_batch_reward 5.188337643941243 step 35430\n",
      "ave_batch_loss 10.580467647976345 step 35430\n",
      "ave_batch_reward 5.116284158494738 step 35540\n",
      "ave_batch_loss 10.037200927734375 step 35540\n",
      "ave_batch_reward 5.0885317590501575 step 35650\n",
      "ave_batch_loss 10.123948468102348 step 35650\n",
      "ave_batch_reward 5.276372167799208 step 35760\n",
      "ave_batch_loss 10.447437286376953 step 35760\n",
      "ave_batch_reward 5.216035154130724 step 35870\n",
      "ave_batch_loss 10.581385718451607 step 35870\n",
      "ave_batch_reward 5.372273392147488 step 35980\n",
      "ave_batch_loss 11.025276184082031 step 35980\n",
      "ave_batch_reward 5.021937555736965 step 36090\n",
      "ave_batch_loss 10.158259921603733 step 36090\n",
      "ave_batch_reward 5.130973021189372 step 36200\n",
      "ave_batch_loss 10.048778427971733 step 36200\n",
      "ave_batch_reward 5.1570234298706055 step 36310\n",
      "ave_batch_loss 9.825303660498726 step 36310\n",
      "ave_batch_reward 5.082008414798313 step 36420\n",
      "ave_batch_loss 10.503312746683756 step 36420\n",
      "ave_batch_reward 5.211574633916219 step 36530\n",
      "ave_batch_loss 9.764670530954996 step 36530\n",
      "ave_batch_reward 5.158913241492377 step 36640\n",
      "ave_batch_loss 10.190627892812094 step 36640\n",
      "ave_batch_reward 5.288125011656019 step 36750\n",
      "ave_batch_loss 10.44974316491021 step 36750\n",
      "ave_batch_reward 5.459675841861301 step 36860\n",
      "ave_batch_loss 10.722930166456434 step 36860\n",
      "ave_batch_reward 5.044851806428698 step 36970\n",
      "ave_batch_loss 10.880443467034233 step 36970\n",
      "ave_batch_reward 5.516608953475952 step 37080\n",
      "ave_batch_loss 11.06969780392117 step 37080\n",
      "ave_batch_reward 5.1881435712178545 step 37190\n",
      "ave_batch_loss 10.478403197394478 step 37190\n",
      "ave_batch_reward 4.875045829349094 step 37300\n",
      "ave_batch_loss 9.916576544443766 step 37300\n",
      "ave_batch_reward 5.344529469807942 step 37410\n",
      "ave_batch_loss 10.232096883985731 step 37410\n",
      "ave_batch_reward 4.9603708320193824 step 37520\n",
      "ave_batch_loss 9.379867606692844 step 37520\n",
      "ave_batch_reward 5.15588903427124 step 37630\n",
      "ave_batch_loss 9.485247929890951 step 37630\n",
      "ave_batch_reward 4.903274377187093 step 37740\n",
      "ave_batch_loss 9.808690071105957 step 37740\n",
      "ave_batch_reward 5.256159994337294 step 37850\n",
      "ave_batch_loss 10.286500506930881 step 37850\n",
      "ave_batch_reward 5.049489074283176 step 37960\n",
      "ave_batch_loss 9.231216112772623 step 37960\n",
      "ave_batch_reward 5.1325159602695045 step 38070\n",
      "ave_batch_loss 10.1459412044949 step 38070\n",
      "ave_batch_reward 5.244678444332546 step 38180\n",
      "ave_batch_loss 9.989969041612413 step 38180\n",
      "ave_batch_reward 5.2275875674353705 step 38290\n",
      "ave_batch_loss 10.682309998406303 step 38290\n",
      "ave_batch_reward 5.408936341603597 step 38400\n",
      "ave_batch_loss 10.892091751098633 step 38400\n",
      "ave_batch_reward 5.209489981333415 step 38510\n",
      "ave_batch_loss 9.555290593041313 step 38510\n",
      "ave_batch_reward 5.1363325119018555 step 38620\n",
      "ave_batch_loss 10.089563793606228 step 38620\n",
      "ave_batch_reward 5.0956178771124945 step 38730\n",
      "ave_batch_loss 10.302390734354654 step 38730\n",
      "ave_batch_reward 5.074141343434651 step 38840\n",
      "ave_batch_loss 10.002431551615397 step 38840\n",
      "ave_batch_reward 5.103191057840983 step 38950\n",
      "ave_batch_loss 9.95387167400784 step 38950\n",
      "ave_batch_reward 5.096178584628635 step 39060\n",
      "ave_batch_loss 9.895612716674805 step 39060\n",
      "ave_batch_reward 5.3429759873284235 step 39170\n",
      "ave_batch_loss 10.549405521816677 step 39170\n",
      "ave_batch_reward 5.065368069542779 step 39280\n",
      "ave_batch_loss 10.644756740993923 step 39280\n",
      "ave_batch_reward 5.302132606506348 step 39390\n",
      "ave_batch_loss 9.85131115383572 step 39390\n",
      "ave_batch_reward 4.9955112669203015 step 39500\n",
      "ave_batch_loss 9.804766654968262 step 39500\n",
      "ave_batch_reward 5.42206883430481 step 39610\n",
      "ave_batch_loss 10.904675589667427 step 39610\n",
      "ave_batch_reward 5.165056890911526 step 39720\n",
      "ave_batch_loss 10.93368297153049 step 39720\n",
      "ave_batch_reward 4.938933240042792 step 39830\n",
      "ave_batch_loss 10.475212944878471 step 39830\n",
      "ave_batch_reward 5.036688778135511 step 39940\n",
      "ave_batch_loss 9.637767791748047 step 39940\n",
      "ave_batch_reward 5.117171711391872 step 40050\n",
      "ave_batch_loss 10.28131432003445 step 40050\n",
      "ave_batch_reward 5.2204957538180885 step 40160\n",
      "ave_batch_loss 10.723553445604113 step 40160\n",
      "ave_batch_reward 5.2474724186791315 step 40270\n",
      "ave_batch_loss 10.279862191942003 step 40270\n",
      "ave_batch_reward 5.3764040735032825 step 40380\n",
      "ave_batch_loss 11.082843674553764 step 40380\n",
      "ave_batch_reward 5.233179675208198 step 40490\n",
      "ave_batch_loss 11.22862794664171 step 40490\n",
      "ave_batch_reward 5.3081476423475475 step 40600\n",
      "ave_batch_loss 10.772632598876953 step 40600\n",
      "ave_batch_reward 5.191920439402263 step 40710\n",
      "ave_batch_loss 10.492062462700737 step 40710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 5.143732865651448 step 40820\n",
      "ave_batch_loss 10.990800751580132 step 40820\n",
      "ave_batch_reward 5.308857176038954 step 40930\n",
      "ave_batch_loss 10.934568405151367 step 40930\n",
      "ave_batch_reward 5.185686376359728 step 41040\n",
      "ave_batch_loss 10.428281784057617 step 41040\n",
      "ave_batch_reward 5.404014958275689 step 41150\n",
      "ave_batch_loss 9.994269476996529 step 41150\n",
      "ave_batch_reward 5.116740279727512 step 41260\n",
      "ave_batch_loss 9.893460591634115 step 41260\n",
      "ave_batch_reward 5.239932060241699 step 41370\n",
      "ave_batch_loss 9.63934294382731 step 41370\n",
      "ave_batch_reward 5.137573136223687 step 41480\n",
      "ave_batch_loss 10.48480913374159 step 41480\n",
      "ave_batch_reward 5.274077415466309 step 41590\n",
      "ave_batch_loss 10.920336405436197 step 41590\n",
      "ave_batch_reward 5.345853964487712 step 41700\n",
      "ave_batch_loss 11.065010070800781 step 41700\n",
      "ave_batch_reward 5.28741807407803 step 41810\n",
      "ave_batch_loss 10.980045000712076 step 41810\n",
      "ave_batch_reward 5.127713044484456 step 41920\n",
      "ave_batch_loss 10.38546699947781 step 41920\n",
      "ave_batch_reward 5.060207049051921 step 42030\n",
      "ave_batch_loss 10.552822430928549 step 42030\n",
      "ave_batch_reward 5.559174140294393 step 42140\n",
      "ave_batch_loss 10.86124430762397 step 42140\n",
      "ave_batch_reward 5.091413127051459 step 42250\n",
      "ave_batch_loss 9.975576400756836 step 42250\n",
      "ave_batch_reward 5.092964066399468 step 42360\n",
      "ave_batch_loss 9.287241670820448 step 42360\n",
      "ave_batch_reward 5.09587902492947 step 42470\n",
      "ave_batch_loss 10.001267115275065 step 42470\n",
      "ave_batch_reward 5.126221789254083 step 42580\n",
      "ave_batch_loss 10.244872623019749 step 42580\n",
      "ave_batch_reward 5.086934195624457 step 42690\n",
      "ave_batch_loss 10.174788210127089 step 42690\n",
      "ave_batch_reward 4.892897023095025 step 42800\n",
      "ave_batch_loss 9.96894317203098 step 42800\n",
      "ave_batch_reward 4.986203670501709 step 42910\n",
      "ave_batch_loss 9.771146933237711 step 42910\n",
      "ave_batch_reward 5.131359391742283 step 43020\n",
      "ave_batch_loss 9.806773715549046 step 43020\n",
      "ave_batch_reward 5.201613532172309 step 43130\n",
      "ave_batch_loss 10.498009469774034 step 43130\n",
      "ave_batch_reward 5.105822987026638 step 43240\n",
      "ave_batch_loss 10.808573087056478 step 43240\n",
      "ave_batch_reward 5.336887730492486 step 43350\n",
      "ave_batch_loss 10.833613183763292 step 43350\n",
      "ave_batch_reward 5.0941254827711315 step 43460\n",
      "ave_batch_loss 9.995565308464897 step 43460\n",
      "ave_batch_reward 5.06099549929301 step 43570\n",
      "ave_batch_loss 9.587672657436794 step 43570\n",
      "ave_batch_reward 4.9560825559828015 step 43680\n",
      "ave_batch_loss 9.774346669514975 step 43680\n",
      "ave_batch_reward 5.204898251427545 step 43790\n",
      "ave_batch_loss 9.537410842047798 step 43790\n",
      "ave_batch_reward 5.108347045050727 step 43900\n",
      "ave_batch_loss 9.96444363064236 step 43900\n",
      "ave_batch_reward 5.273789935641819 step 44010\n",
      "ave_batch_loss 10.940412203470865 step 44010\n",
      "ave_batch_reward 5.208519326315986 step 44120\n",
      "ave_batch_loss 10.727530479431152 step 44120\n",
      "ave_batch_reward 5.059021843804254 step 44230\n",
      "ave_batch_loss 10.492483033074272 step 44230\n",
      "ave_batch_reward 5.138509379492866 step 44340\n",
      "ave_batch_loss 8.944906287723118 step 44340\n",
      "ave_batch_reward 5.048328876495361 step 44450\n",
      "ave_batch_loss 10.350313186645508 step 44450\n",
      "ave_batch_reward 5.2711785899268255 step 44560\n",
      "ave_batch_loss 10.911386277940538 step 44560\n",
      "ave_batch_reward 5.090808338589138 step 44670\n",
      "ave_batch_loss 10.537438286675346 step 44670\n",
      "ave_batch_reward 5.202044645945231 step 44780\n",
      "ave_batch_loss 10.21288013458252 step 44780\n",
      "ave_batch_reward 5.166748099856907 step 44890\n",
      "ave_batch_loss 10.319792853461372 step 44890\n",
      "ave_batch_reward 5.128289514117771 step 45000\n",
      "ave_batch_loss 10.147347768147787 step 45000\n",
      "ave_batch_reward 5.233254671096802 step 45110\n",
      "ave_batch_loss 9.550897704230415 step 45110\n",
      "ave_batch_reward 5.006738477283054 step 45220\n",
      "ave_batch_loss 10.198860698276096 step 45220\n",
      "ave_batch_reward 5.242544968922933 step 45330\n",
      "ave_batch_loss 10.740292761060926 step 45330\n",
      "ave_batch_reward 5.3127832942538795 step 45440\n",
      "ave_batch_loss 11.182370079888237 step 45440\n",
      "ave_batch_reward 5.189219050937229 step 45550\n",
      "ave_batch_loss 11.125351905822754 step 45550\n",
      "ave_batch_reward 5.231052822536892 step 45660\n",
      "ave_batch_loss 10.579978730943468 step 45660\n",
      "ave_batch_reward 5.194462723202175 step 45770\n",
      "ave_batch_loss 10.942570792304146 step 45770\n",
      "ave_batch_reward 5.096662415398492 step 45880\n",
      "ave_batch_loss 10.161724938286675 step 45880\n",
      "ave_batch_reward 5.100013679928249 step 45990\n",
      "ave_batch_loss 9.868829674190945 step 45990\n",
      "ave_batch_reward 5.355210410224067 step 46100\n",
      "ave_batch_loss 10.118207189771864 step 46100\n",
      "ave_batch_reward 5.094620545705159 step 46210\n",
      "ave_batch_loss 10.098178757561577 step 46210\n",
      "ave_batch_reward 5.292974948883057 step 46320\n",
      "ave_batch_loss 10.687993049621582 step 46320\n",
      "ave_batch_reward 5.009572664896647 step 46430\n",
      "ave_batch_loss 10.633576605055067 step 46430\n",
      "ave_batch_reward 5.0716615782843695 step 46540\n",
      "ave_batch_loss 10.262000189887154 step 46540\n",
      "ave_batch_reward 5.293736060460408 step 46650\n",
      "ave_batch_loss 10.614439222547743 step 46650\n",
      "ave_batch_reward 4.833775069978502 step 46760\n",
      "ave_batch_loss 11.31974728902181 step 46760\n",
      "ave_batch_reward 5.404623084598118 step 46870\n",
      "ave_batch_loss 10.383359379238552 step 46870\n",
      "ave_batch_reward 5.006152815288967 step 46980\n",
      "ave_batch_loss 9.592203723059761 step 46980\n",
      "ave_batch_reward 5.179427040947808 step 47090\n",
      "ave_batch_loss 10.350800938076443 step 47090\n",
      "ave_batch_reward 5.298872470855713 step 47200\n",
      "ave_batch_loss 10.990520371331108 step 47200\n",
      "ave_batch_reward 4.94902065065172 step 47310\n",
      "ave_batch_loss 9.349487463633219 step 47310\n",
      "ave_batch_reward 5.159077379438612 step 47420\n",
      "ave_batch_loss 10.196652094523111 step 47420\n",
      "ave_batch_reward 5.1468114323086205 step 47530\n",
      "ave_batch_loss 9.75253274705675 step 47530\n",
      "ave_batch_reward 5.253015889061822 step 47640\n",
      "ave_batch_loss 9.647228717803955 step 47640\n",
      "ave_batch_reward 5.260668330722385 step 47750\n",
      "ave_batch_loss 10.16098149617513 step 47750\n",
      "ave_batch_reward 5.221105734507243 step 47860\n",
      "ave_batch_loss 9.997561560736763 step 47860\n",
      "ave_batch_reward 5.085143354203966 step 47970\n",
      "ave_batch_loss 10.179766549004448 step 47970\n",
      "ave_batch_reward 5.196447690327962 step 48080\n",
      "ave_batch_loss 10.958132637871635 step 48080\n",
      "ave_batch_reward 5.015313731299506 step 48190\n",
      "ave_batch_loss 10.226400746239555 step 48190\n",
      "ave_batch_reward 5.060011227925618 step 48300\n",
      "ave_batch_loss 9.496181964874268 step 48300\n",
      "ave_batch_reward 5.166926966773139 step 48410\n",
      "ave_batch_loss 10.258016268412272 step 48410\n",
      "ave_batch_reward 5.236661672592163 step 48520\n",
      "ave_batch_loss 10.974447038438585 step 48520\n",
      "ave_batch_reward 5.505185816023085 step 48630\n",
      "ave_batch_loss 11.497298982408312 step 48630\n",
      "ave_batch_reward 5.115059852600098 step 48740\n",
      "ave_batch_loss 10.774783982170952 step 48740\n",
      "ave_batch_reward 5.100478516684638 step 48850\n",
      "ave_batch_loss 10.055221981472439 step 48850\n",
      "ave_batch_reward 5.155651834275988 step 48960\n",
      "ave_batch_loss 10.263174586825901 step 48960\n",
      "ave_batch_reward 5.215206940968831 step 49070\n",
      "ave_batch_loss 9.655955155690512 step 49070\n",
      "ave_batch_reward 5.2683090103997126 step 49180\n",
      "ave_batch_loss 10.906858232286242 step 49180\n",
      "ave_batch_reward 5.374137666490343 step 49290\n",
      "ave_batch_loss 10.775482495625814 step 49290\n",
      "ave_batch_reward 5.265685160954793 step 49400\n",
      "ave_batch_loss 10.759791586134169 step 49400\n",
      "ave_batch_reward 5.046095609664917 step 49510\n",
      "ave_batch_loss 9.928446080949572 step 49510\n",
      "ave_batch_reward 5.420861456129286 step 49620\n",
      "ave_batch_loss 10.4967254002889 step 49620\n",
      "ave_batch_reward 5.135027196672228 step 49730\n",
      "ave_batch_loss 10.307484414842394 step 49730\n",
      "ave_batch_reward 5.206255965762669 step 49840\n",
      "ave_batch_loss 10.038769933912489 step 49840\n",
      "ave_batch_reward 5.096820990244548 step 49950\n",
      "ave_batch_loss 10.68691603342692 step 49950\n",
      "ave_batch_reward 5.065897226333618 step 50060\n",
      "ave_batch_loss 10.49310376909044 step 50060\n",
      "ave_batch_reward 5.107142315970527 step 50170\n",
      "ave_batch_loss 10.061750253041586 step 50170\n",
      "ave_batch_reward 4.986684295866224 step 50280\n",
      "ave_batch_loss 9.716419008043077 step 50280\n",
      "ave_batch_reward 5.471926344765557 step 50390\n",
      "ave_batch_loss 10.789554172092014 step 50390\n",
      "ave_batch_reward 5.110047022501628 step 50500\n",
      "ave_batch_loss 10.085610919528538 step 50500\n",
      "ave_batch_reward 5.133830494350857 step 50610\n",
      "ave_batch_loss 10.431312772962782 step 50610\n",
      "ave_batch_reward 5.181382947497898 step 50720\n",
      "ave_batch_loss 9.753647380405003 step 50720\n",
      "ave_batch_reward 5.117393334706624 step 50830\n",
      "ave_batch_loss 9.969546212090385 step 50830\n",
      "ave_batch_reward 5.293522675832112 step 50940\n",
      "ave_batch_loss 10.603744294908312 step 50940\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 5.208127074771458 step 51050\n",
      "ave_batch_loss 11.141449610392252 step 51050\n",
      "ave_batch_reward 5.28033791648017 step 51160\n",
      "ave_batch_loss 11.062172465854221 step 51160\n",
      "ave_batch_reward 5.164061228434245 step 51270\n",
      "ave_batch_loss 10.087337017059326 step 51270\n",
      "ave_batch_reward 5.259736167060004 step 51380\n",
      "ave_batch_loss 10.50805950164795 step 51380\n",
      "ave_batch_reward 5.1154369248284235 step 51490\n",
      "ave_batch_loss 9.998206297556559 step 51490\n",
      "ave_batch_reward 5.290635744730632 step 51600\n",
      "ave_batch_loss 9.926471869150797 step 51600\n",
      "ave_batch_reward 5.19767411549886 step 51710\n",
      "ave_batch_loss 10.967096010843912 step 51710\n",
      "ave_batch_reward 5.496160560184055 step 51820\n",
      "ave_batch_loss 11.084408654106987 step 51820\n",
      "ave_batch_reward 5.2479141553243 step 51930\n",
      "ave_batch_loss 11.043375968933105 step 51930\n",
      "ave_batch_reward 5.0048148896959095 step 52040\n",
      "ave_batch_loss 10.500757641262478 step 52040\n",
      "ave_batch_reward 5.122239854600695 step 52150\n",
      "ave_batch_loss 10.034801165262857 step 52150\n",
      "ave_batch_reward 4.91571503215366 step 52260\n",
      "ave_batch_loss 9.095930364396837 step 52260\n",
      "ave_batch_reward 5.131109184688992 step 52370\n",
      "ave_batch_loss 9.673136022355822 step 52370\n",
      "ave_batch_reward 5.061095979478624 step 52480\n",
      "ave_batch_loss 9.402934127383762 step 52480\n",
      "ave_batch_reward 5.189684444003635 step 52590\n",
      "ave_batch_loss 10.378513442145454 step 52590\n",
      "ave_batch_reward 5.369075430764092 step 52700\n",
      "ave_batch_loss 10.997208065456814 step 52700\n",
      "ave_batch_reward 5.225338247087267 step 52810\n",
      "ave_batch_loss 10.762079980638292 step 52810\n",
      "ave_batch_reward 5.3479888968997535 step 52920\n",
      "ave_batch_loss 10.922794553968641 step 52920\n",
      "ave_batch_reward 5.012394110361735 step 53030\n",
      "ave_batch_loss 10.083790196312798 step 53030\n",
      "ave_batch_reward 5.111266613006592 step 53140\n",
      "ave_batch_loss 9.787443055046928 step 53140\n",
      "ave_batch_reward 5.334633615281847 step 53250\n",
      "ave_batch_loss 10.638448609246147 step 53250\n",
      "ave_batch_reward 5.2638062371148004 step 53360\n",
      "ave_batch_loss 11.07387246025933 step 53360\n",
      "ave_batch_reward 5.034233570098877 step 53470\n",
      "ave_batch_loss 10.061698383755154 step 53470\n",
      "ave_batch_reward 5.349354134665595 step 53580\n",
      "ave_batch_loss 10.485329627990723 step 53580\n",
      "ave_batch_reward 5.285832987891303 step 53690\n",
      "ave_batch_loss 10.219633102416992 step 53690\n",
      "ave_batch_reward 5.278677145640056 step 53800\n",
      "ave_batch_loss 9.91596926583184 step 53800\n",
      "ave_batch_reward 5.202129893832737 step 53910\n",
      "ave_batch_loss 10.997127850850424 step 53910\n",
      "ave_batch_reward 5.265850490993923 step 54020\n",
      "ave_batch_loss 9.67828400929769 step 54020\n",
      "ave_batch_reward 4.993228170606825 step 54130\n",
      "ave_batch_loss 10.571789741516113 step 54130\n",
      "ave_batch_reward 5.031521293852064 step 54240\n",
      "ave_batch_loss 9.292273892296684 step 54240\n",
      "ave_batch_reward 5.061847421858046 step 54350\n",
      "ave_batch_loss 9.665940390692818 step 54350\n",
      "ave_batch_reward 5.083304511176215 step 54460\n",
      "ave_batch_loss 10.239456918504503 step 54460\n",
      "ave_batch_reward 5.231688393486871 step 54570\n",
      "ave_batch_loss 10.694267272949219 step 54570\n",
      "ave_batch_reward 5.0839780701531305 step 54680\n",
      "ave_batch_loss 10.731307453579372 step 54680\n",
      "ave_batch_reward 5.282541169060601 step 54790\n",
      "ave_batch_loss 10.99808661142985 step 54790\n",
      "ave_batch_reward 5.389741155836317 step 54900\n",
      "ave_batch_loss 10.86213207244873 step 54900\n",
      "ave_batch_reward 5.063710742526585 step 55010\n",
      "ave_batch_loss 10.49467584821913 step 55010\n",
      "ave_batch_reward 5.131658024258083 step 55120\n",
      "ave_batch_loss 9.721179061465794 step 55120\n",
      "ave_batch_reward 5.141159163581 step 55230\n",
      "ave_batch_loss 10.55224174923367 step 55230\n",
      "ave_batch_reward 5.218196551005046 step 55340\n",
      "ave_batch_loss 10.679916911655003 step 55340\n",
      "ave_batch_reward 5.27116780810886 step 55450\n",
      "ave_batch_loss 10.933398988511827 step 55450\n",
      "ave_batch_reward 5.177393171522352 step 55560\n",
      "ave_batch_loss 10.458006117078993 step 55560\n",
      "ave_batch_reward 5.056935257381863 step 55670\n",
      "ave_batch_loss 9.764274597167969 step 55670\n",
      "ave_batch_reward 5.20939752790663 step 55780\n",
      "ave_batch_loss 10.77123016781277 step 55780\n",
      "ave_batch_reward 5.388471364974976 step 55890\n",
      "ave_batch_loss 11.039464208814833 step 55890\n",
      "ave_batch_reward 5.240327941046821 step 56000\n",
      "ave_batch_loss 11.292319615681967 step 56000\n",
      "ave_batch_reward 5.191723823547363 step 56110\n",
      "ave_batch_loss 10.684099409315321 step 56110\n",
      "ave_batch_reward 5.208440860112508 step 56220\n",
      "ave_batch_loss 10.94502502017551 step 56220\n",
      "ave_batch_reward 5.206391122606066 step 56330\n",
      "ave_batch_loss 10.550680160522461 step 56330\n",
      "ave_batch_reward 5.1627182430691185 step 56440\n",
      "ave_batch_loss 9.5843718846639 step 56440\n",
      "ave_batch_reward 4.775500880347358 step 56550\n",
      "ave_batch_loss 9.114221413930258 step 56550\n",
      "ave_batch_reward 5.067589177025689 step 56660\n",
      "ave_batch_loss 9.685153378380669 step 56660\n",
      "ave_batch_reward 5.109570821126302 step 56770\n",
      "ave_batch_loss 9.785321871439615 step 56770\n",
      "ave_batch_reward 5.004778544108073 step 56880\n",
      "ave_batch_loss 9.895054393344456 step 56880\n",
      "ave_batch_reward 5.334015581342909 step 56990\n",
      "ave_batch_loss 10.407750023735893 step 56990\n",
      "ave_batch_reward 5.248196919759114 step 57100\n",
      "ave_batch_loss 10.378494474622938 step 57100\n",
      "ave_batch_reward 5.342403941684299 step 57210\n",
      "ave_batch_loss 10.952886687384712 step 57210\n",
      "ave_batch_reward 5.097737100389269 step 57320\n",
      "ave_batch_loss 10.380258666144478 step 57320\n",
      "ave_batch_reward 4.968601544698079 step 57430\n",
      "ave_batch_loss 10.495939572652182 step 57430\n",
      "ave_batch_reward 5.259193526373969 step 57540\n",
      "ave_batch_loss 10.409254921807182 step 57540\n",
      "ave_batch_reward 5.08514044019911 step 57650\n",
      "ave_batch_loss 10.598394287957085 step 57650\n",
      "ave_batch_reward 5.285828166537815 step 57760\n",
      "ave_batch_loss 11.024579577975803 step 57760\n",
      "ave_batch_reward 4.97392299440172 step 57870\n",
      "ave_batch_loss 10.164940410190159 step 57870\n",
      "ave_batch_reward 5.181462552812365 step 57980\n",
      "ave_batch_loss 9.91429222954644 step 57980\n",
      "ave_batch_reward 5.129566537009345 step 58090\n",
      "ave_batch_loss 10.727016343010796 step 58090\n",
      "ave_batch_reward 5.151742617289226 step 58200\n",
      "ave_batch_loss 11.12944867875841 step 58200\n",
      "ave_batch_reward 5.366790718502468 step 58310\n",
      "ave_batch_loss 10.389740308125814 step 58310\n",
      "ave_batch_reward 5.139325141906738 step 58420\n",
      "ave_batch_loss 10.893160925971138 step 58420\n",
      "ave_batch_reward 5.418709595998128 step 58530\n",
      "ave_batch_loss 10.629771762424046 step 58530\n",
      "ave_batch_reward 5.17481263478597 step 58640\n",
      "ave_batch_loss 10.535465134514702 step 58640\n",
      "ave_batch_reward 5.295018037160237 step 58750\n",
      "ave_batch_loss 11.096842765808105 step 58750\n",
      "ave_batch_reward 5.155783441331652 step 58860\n",
      "ave_batch_loss 10.327679104275173 step 58860\n",
      "ave_batch_reward 4.934738530053033 step 58970\n",
      "ave_batch_loss 10.571817715962728 step 58970\n",
      "ave_batch_reward 5.406077490912543 step 59080\n",
      "ave_batch_loss 10.394342422485352 step 59080\n",
      "ave_batch_reward 4.855662981669108 step 59190\n",
      "ave_batch_loss 9.431645287407768 step 59190\n",
      "ave_batch_reward 5.185791545444065 step 59300\n",
      "ave_batch_loss 10.3268674214681 step 59300\n",
      "ave_batch_reward 5.0764767328898115 step 59410\n",
      "ave_batch_loss 9.49522320429484 step 59410\n",
      "ave_batch_reward 5.066509352789985 step 59520\n",
      "ave_batch_loss 9.84709029727512 step 59520\n",
      "ave_batch_reward 5.049603515201145 step 59630\n",
      "ave_batch_loss 10.739460521274143 step 59630\n",
      "ave_batch_reward 5.027493503358629 step 59740\n",
      "ave_batch_loss 9.15386242336697 step 59740\n",
      "ave_batch_reward 5.115758313073052 step 59850\n",
      "ave_batch_loss 9.18857447306315 step 59850\n",
      "ave_batch_reward 5.268262545267741 step 59960\n",
      "ave_batch_loss 10.228873252868652 step 59960\n",
      "ave_batch_reward 5.173283471001519 step 60070\n",
      "ave_batch_loss 10.345866945054796 step 60070\n",
      "ave_batch_reward 5.505704773796929 step 60180\n",
      "ave_batch_loss 10.997548421223959 step 60180\n",
      "ave_batch_reward 5.203316238191393 step 60290\n",
      "ave_batch_loss 10.12872282663981 step 60290\n",
      "ave_batch_reward 4.918851190143162 step 60400\n",
      "ave_batch_loss 9.74433347913954 step 60400\n",
      "ave_batch_reward 5.0143686930338545 step 60510\n",
      "ave_batch_loss 9.589426729414198 step 60510\n",
      "ave_batch_reward 5.040993637508816 step 60620\n",
      "ave_batch_loss 9.135614236195883 step 60620\n",
      "ave_batch_reward 5.158497492472331 step 60730\n",
      "ave_batch_loss 10.206283781263563 step 60730\n",
      "ave_batch_reward 5.409708076053196 step 60840\n",
      "ave_batch_loss 10.929415278964573 step 60840\n",
      "ave_batch_reward 5.158414178424412 step 60950\n",
      "ave_batch_loss 9.961719830830893 step 60950\n",
      "ave_batch_reward 5.161228789223565 step 61060\n",
      "ave_batch_loss 9.99137454562717 step 61060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 5.0342640611860485 step 61170\n",
      "ave_batch_loss 8.839059935675728 step 61170\n",
      "ave_batch_reward 5.078638262218899 step 61280\n",
      "ave_batch_loss 9.882431772020128 step 61280\n",
      "ave_batch_reward 4.927578952577379 step 61390\n",
      "ave_batch_loss 9.820196257697212 step 61390\n",
      "ave_batch_reward 5.189442740546332 step 61500\n",
      "ave_batch_loss 10.426003138224283 step 61500\n",
      "ave_batch_reward 5.105572541554769 step 61610\n",
      "ave_batch_loss 10.06177446577284 step 61610\n",
      "ave_batch_reward 5.302096260918511 step 61720\n",
      "ave_batch_loss 10.54061190287272 step 61720\n",
      "ave_batch_reward 5.040703747007582 step 61830\n",
      "ave_batch_loss 9.21821599536472 step 61830\n",
      "ave_batch_reward 4.937919722663032 step 61940\n",
      "ave_batch_loss 10.193031205071343 step 61940\n",
      "ave_batch_reward 4.843268182542589 step 62050\n",
      "ave_batch_loss 9.816924201117622 step 62050\n",
      "ave_batch_reward 4.92431214120653 step 62160\n",
      "ave_batch_loss 9.347163518269857 step 62160\n",
      "ave_batch_reward 5.1809073024325905 step 62270\n",
      "ave_batch_loss 10.328520350986057 step 62270\n",
      "ave_batch_reward 5.335426065656874 step 62380\n",
      "ave_batch_loss 11.399619420369467 step 62380\n",
      "ave_batch_reward 5.234573576185438 step 62490\n",
      "ave_batch_loss 11.03151469760471 step 62490\n",
      "ave_batch_reward 5.360786888334486 step 62600\n",
      "ave_batch_loss 10.785760349697536 step 62600\n",
      "ave_batch_reward 4.97889863120185 step 62710\n",
      "ave_batch_loss 10.08121214972602 step 62710\n",
      "ave_batch_reward 5.210642337799072 step 62820\n",
      "ave_batch_loss 9.645777490403917 step 62820\n",
      "ave_batch_reward 5.158096366458469 step 62930\n",
      "ave_batch_loss 10.967489666408962 step 62930\n",
      "ave_batch_reward 5.212166574266222 step 63040\n",
      "ave_batch_loss 10.41644318898519 step 63040\n",
      "ave_batch_reward 5.383331775665283 step 63150\n",
      "ave_batch_loss 10.770661036173502 step 63150\n",
      "ave_batch_reward 5.259635819329156 step 63260\n",
      "ave_batch_loss 10.902756690979004 step 63260\n",
      "ave_batch_reward 5.2677525414360895 step 63370\n",
      "ave_batch_loss 9.85949601067437 step 63370\n",
      "ave_batch_reward 5.156046814388699 step 63480\n",
      "ave_batch_loss 10.501483599344889 step 63480\n",
      "ave_batch_reward 5.174935075971815 step 63590\n",
      "ave_batch_loss 10.693322605556911 step 63590\n",
      "ave_batch_reward 4.976433700985378 step 63700\n",
      "ave_batch_loss 9.374508592817518 step 63700\n",
      "ave_batch_reward 5.09972686237759 step 63810\n",
      "ave_batch_loss 10.042608578999838 step 63810\n",
      "ave_batch_reward 5.154143863254124 step 63920\n",
      "ave_batch_loss 10.284781138102213 step 63920\n",
      "ave_batch_reward 5.196524302164714 step 64030\n",
      "ave_batch_loss 10.993857383728027 step 64030\n",
      "ave_batch_reward 5.080573770734999 step 64140\n",
      "ave_batch_loss 10.362281799316406 step 64140\n",
      "ave_batch_reward 5.360678831736247 step 64250\n",
      "ave_batch_loss 11.01993073357476 step 64250\n",
      "ave_batch_reward 5.0558581882052955 step 64360\n",
      "ave_batch_loss 10.449109925164116 step 64360\n",
      "ave_batch_reward 5.077600373162164 step 64470\n",
      "ave_batch_loss 9.043268203735352 step 64470\n",
      "ave_batch_reward 5.138774183061388 step 64580\n",
      "ave_batch_loss 9.48546838760376 step 64580\n",
      "ave_batch_reward 5.136060343848334 step 64690\n",
      "ave_batch_loss 10.441787825690376 step 64690\n",
      "ave_batch_reward 5.327483971913655 step 64800\n",
      "ave_batch_loss 10.43695460425483 step 64800\n",
      "ave_batch_reward 5.173074510362413 step 64910\n",
      "ave_batch_loss 10.624144342210558 step 64910\n",
      "ave_batch_reward 5.190548049079047 step 65020\n",
      "ave_batch_loss 10.288671970367432 step 65020\n",
      "ave_batch_reward 5.238393518659803 step 65130\n",
      "ave_batch_loss 10.687803162468803 step 65130\n",
      "ave_batch_reward 5.249682638380262 step 65240\n",
      "ave_batch_loss 10.783452139960396 step 65240\n",
      "ave_batch_reward 5.313823964860704 step 65350\n",
      "ave_batch_loss 10.66147412194146 step 65350\n",
      "ave_batch_reward 5.267771667904324 step 65460\n",
      "ave_batch_loss 10.881016201443142 step 65460\n",
      "ave_batch_reward 5.133023685879177 step 65570\n",
      "ave_batch_loss 10.94121011098226 step 65570\n",
      "ave_batch_reward 5.206164201100667 step 65680\n",
      "ave_batch_loss 10.54576047261556 step 65680\n",
      "ave_batch_reward 5.1871900293562145 step 65790\n",
      "ave_batch_loss 10.451140615675184 step 65790\n",
      "ave_batch_reward 5.1652140617370605 step 65900\n",
      "ave_batch_loss 10.48909748925103 step 65900\n",
      "ave_batch_reward 5.424600654178196 step 66010\n",
      "ave_batch_loss 10.981924904717339 step 66010\n",
      "ave_batch_reward 5.25699355867174 step 66120\n",
      "ave_batch_loss 10.888577143351236 step 66120\n",
      "ave_batch_reward 5.255101256900364 step 66230\n",
      "ave_batch_loss 10.3396331999037 step 66230\n",
      "ave_batch_reward 5.156905651092529 step 66340\n",
      "ave_batch_loss 10.242393493652344 step 66340\n",
      "ave_batch_reward 5.170618481106228 step 66450\n",
      "ave_batch_loss 10.022029134962294 step 66450\n",
      "ave_batch_reward 5.043960730234782 step 66560\n",
      "ave_batch_loss 9.82159317864312 step 66560\n",
      "ave_batch_reward 5.085646629333496 step 66670\n",
      "ave_batch_loss 10.613456302218967 step 66670\n",
      "ave_batch_reward 5.387539333767361 step 66780\n",
      "ave_batch_loss 11.521309852600098 step 66780\n",
      "ave_batch_reward 5.165568086836073 step 66890\n",
      "ave_batch_loss 9.31972206963433 step 66890\n",
      "ave_batch_reward 5.2523579597473145 step 67000\n",
      "ave_batch_loss 9.792126125759548 step 67000\n",
      "ave_batch_reward 5.160005225075616 step 67110\n",
      "ave_batch_loss 10.220251507229275 step 67110\n",
      "ave_batch_reward 5.238209459516737 step 67220\n",
      "ave_batch_loss 10.697404119703505 step 67220\n",
      "ave_batch_reward 5.151772181193034 step 67330\n",
      "ave_batch_loss 10.293790499369303 step 67330\n",
      "ave_batch_reward 4.984768841001722 step 67440\n",
      "ave_batch_loss 9.52193832397461 step 67440\n",
      "ave_batch_reward 5.136613051096599 step 67550\n",
      "ave_batch_loss 10.060520278082954 step 67550\n",
      "ave_batch_reward 5.269935184054905 step 67660\n",
      "ave_batch_loss 10.887518564860025 step 67660\n",
      "ave_batch_reward 5.27522161271837 step 67770\n",
      "ave_batch_loss 10.81201140085856 step 67770\n",
      "ave_batch_reward 5.224531067742242 step 67880\n",
      "ave_batch_loss 10.07916620042589 step 67880\n",
      "ave_batch_reward 5.181295024024116 step 67990\n",
      "ave_batch_loss 10.42749383714464 step 67990\n",
      "ave_batch_reward 5.149868011474609 step 68100\n",
      "ave_batch_loss 10.202188544803196 step 68100\n",
      "ave_batch_reward 5.3031014866299095 step 68210\n",
      "ave_batch_loss 11.114511489868164 step 68210\n",
      "ave_batch_reward 5.255010498894586 step 68320\n",
      "ave_batch_loss 10.55567455291748 step 68320\n",
      "ave_batch_reward 5.109039306640625 step 68430\n",
      "ave_batch_loss 10.360655254787869 step 68430\n",
      "ave_batch_reward 5.1238235367669 step 68540\n",
      "ave_batch_loss 9.823133362664116 step 68540\n",
      "ave_batch_reward 5.259618282318115 step 68650\n",
      "ave_batch_loss 10.664665116204155 step 68650\n",
      "ave_batch_reward 5.223783387078179 step 68760\n",
      "ave_batch_loss 10.676592508951822 step 68760\n",
      "ave_batch_reward 5.261891312069363 step 68870\n",
      "ave_batch_loss 10.736048698425293 step 68870\n",
      "ave_batch_reward 5.238303846783108 step 68980\n",
      "ave_batch_loss 10.95869689517551 step 68980\n",
      "ave_batch_reward 5.286122745937771 step 69090\n",
      "ave_batch_loss 11.021185027228462 step 69090\n",
      "ave_batch_reward 5.15763176812066 step 69200\n",
      "ave_batch_loss 10.674750328063965 step 69200\n",
      "ave_batch_reward 5.157308260599772 step 69310\n",
      "ave_batch_loss 9.628439744313559 step 69310\n",
      "ave_batch_reward 4.95401226149665 step 69420\n",
      "ave_batch_loss 9.568598217434353 step 69420\n",
      "ave_batch_reward 5.078303337097168 step 69530\n",
      "ave_batch_loss 9.087658564249674 step 69530\n",
      "ave_batch_reward 5.00903042157491 step 69640\n",
      "ave_batch_loss 9.617890728844536 step 69640\n",
      "ave_batch_reward 5.287595748901367 step 69750\n",
      "ave_batch_loss 10.484231207105848 step 69750\n",
      "ave_batch_reward 5.229040437274509 step 69860\n",
      "ave_batch_loss 9.944650491078695 step 69860\n",
      "ave_batch_reward 4.992800818549262 step 69970\n",
      "ave_batch_loss 9.744887351989746 step 69970\n",
      "ave_batch_reward 5.233850849999322 step 70080\n",
      "ave_batch_loss 9.696965323554146 step 70080\n",
      "ave_batch_reward 5.068357202741835 step 70190\n",
      "ave_batch_loss 10.143346998426649 step 70190\n",
      "ave_batch_reward 5.1537361409929066 step 70300\n",
      "ave_batch_loss 10.219443851047092 step 70300\n",
      "ave_batch_reward 5.03428496254815 step 70410\n",
      "ave_batch_loss 9.550669776068794 step 70410\n",
      "ave_batch_reward 5.3280020289950905 step 70520\n",
      "ave_batch_loss 10.860597080654568 step 70520\n",
      "ave_batch_reward 5.209662172529432 step 70630\n",
      "ave_batch_loss 10.70470831129286 step 70630\n",
      "ave_batch_reward 5.177815384334988 step 70740\n",
      "ave_batch_loss 10.399013731214735 step 70740\n",
      "ave_batch_reward 5.0739668475257025 step 70850\n",
      "ave_batch_loss 9.819397396511501 step 70850\n",
      "ave_batch_reward 5.1015250947740345 step 70960\n",
      "ave_batch_loss 10.175916141933865 step 70960\n",
      "ave_batch_reward 5.099187162187365 step 71070\n",
      "ave_batch_loss 10.176809787750244 step 71070\n",
      "ave_batch_reward 5.105286492241754 step 71180\n",
      "ave_batch_loss 10.56972493065728 step 71180\n",
      "ave_batch_reward 5.258135424719916 step 71290\n",
      "ave_batch_loss 10.678780555725098 step 71290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 4.73583369784885 step 71400\n",
      "ave_batch_loss 10.029064231448704 step 71400\n",
      "ave_batch_reward 5.08882310655382 step 71510\n",
      "ave_batch_loss 9.01286416583591 step 71510\n",
      "ave_batch_reward 5.092113018035889 step 71620\n",
      "ave_batch_loss 10.244057920244005 step 71620\n",
      "ave_batch_reward 5.23761166466607 step 71730\n",
      "ave_batch_loss 10.463149070739746 step 71730\n",
      "ave_batch_reward 5.164229843351576 step 71840\n",
      "ave_batch_loss 10.802684677971733 step 71840\n",
      "ave_batch_reward 5.045222653283013 step 71950\n",
      "ave_batch_loss 10.95126681857639 step 71950\n",
      "ave_batch_reward 5.358484268188477 step 72060\n",
      "ave_batch_loss 10.97456497616238 step 72060\n",
      "ave_batch_reward 5.104195303387112 step 72170\n",
      "ave_batch_loss 10.828447024027506 step 72170\n",
      "ave_batch_reward 5.13822078704834 step 72280\n",
      "ave_batch_loss 9.499467902713352 step 72280\n",
      "ave_batch_reward 5.138306670718723 step 72390\n",
      "ave_batch_loss 10.240410380893284 step 72390\n",
      "ave_batch_reward 5.281153122584025 step 72500\n",
      "ave_batch_loss 9.886225912306044 step 72500\n",
      "ave_batch_reward 4.897865957683987 step 72610\n",
      "ave_batch_loss 10.084897677103678 step 72610\n",
      "ave_batch_reward 5.378437254163954 step 72720\n",
      "ave_batch_loss 10.408629099527994 step 72720\n",
      "ave_batch_reward 5.081244150797526 step 72830\n",
      "ave_batch_loss 10.72528722551134 step 72830\n",
      "ave_batch_reward 5.283679829703437 step 72940\n",
      "ave_batch_loss 10.506788571675619 step 72940\n",
      "ave_batch_reward 5.353025118509929 step 73050\n",
      "ave_batch_loss 10.633566962348091 step 73050\n",
      "ave_batch_reward 5.039046923319499 step 73160\n",
      "ave_batch_loss 11.016093677944607 step 73160\n",
      "ave_batch_reward 5.253126091427273 step 73270\n",
      "ave_batch_loss 9.909779124789768 step 73270\n",
      "ave_batch_reward 5.100771215226915 step 73380\n",
      "ave_batch_loss 9.884998109605577 step 73380\n",
      "ave_batch_reward 5.282835006713867 step 73490\n",
      "ave_batch_loss 10.97668711344401 step 73490\n",
      "ave_batch_reward 5.012331538730198 step 73600\n",
      "ave_batch_loss 10.017715242173937 step 73600\n",
      "ave_batch_reward 5.10879733827379 step 73710\n",
      "ave_batch_loss 9.563068072001139 step 73710\n",
      "ave_batch_reward 4.992685185538398 step 73820\n",
      "ave_batch_loss 9.334859530131022 step 73820\n",
      "ave_batch_reward 5.151158332824707 step 73930\n",
      "ave_batch_loss 10.059089024861654 step 73930\n",
      "ave_batch_reward 5.1776407559712725 step 74040\n",
      "ave_batch_loss 9.76188294092814 step 74040\n",
      "ave_batch_reward 4.894090440538195 step 74150\n",
      "ave_batch_loss 10.362596617804634 step 74150\n",
      "ave_batch_reward 5.250344461864895 step 74260\n",
      "ave_batch_loss 9.76599015129937 step 74260\n",
      "ave_batch_reward 5.18475506040785 step 74370\n",
      "ave_batch_loss 9.874581707848442 step 74370\n",
      "ave_batch_reward 5.226376957363552 step 74480\n",
      "ave_batch_loss 10.15237463845147 step 74480\n",
      "ave_batch_reward 4.970467355516222 step 74590\n",
      "ave_batch_loss 9.525003804100884 step 74590\n",
      "ave_batch_reward 5.390325572755602 step 74700\n",
      "ave_batch_loss 10.338726891411675 step 74700\n",
      "ave_batch_reward 5.128227525287205 step 74810\n",
      "ave_batch_loss 10.476238568623861 step 74810\n",
      "ave_batch_reward 5.304460499021742 step 74920\n",
      "ave_batch_loss 10.822467168172201 step 74920\n",
      "ave_batch_reward 4.9183808432685 step 75030\n",
      "ave_batch_loss 10.250211768680149 step 75030\n",
      "ave_batch_reward 5.287926938798693 step 75140\n",
      "ave_batch_loss 10.604687266879612 step 75140\n",
      "ave_batch_reward 5.208101299073961 step 75250\n",
      "ave_batch_loss 10.591757774353027 step 75250\n",
      "ave_batch_reward 5.08498305744595 step 75360\n",
      "ave_batch_loss 10.13812616136339 step 75360\n",
      "ave_batch_reward 5.258777565426296 step 75470\n",
      "ave_batch_loss 9.460410647922092 step 75470\n",
      "ave_batch_reward 5.043505032857259 step 75580\n",
      "ave_batch_loss 9.612029552459717 step 75580\n",
      "ave_batch_reward 5.304245127571954 step 75690\n",
      "ave_batch_loss 10.20475016699897 step 75690\n",
      "ave_batch_reward 5.124630080329047 step 75800\n",
      "ave_batch_loss 10.304506831698948 step 75800\n",
      "ave_batch_reward 5.151308642493354 step 75910\n",
      "ave_batch_loss 9.649776246812609 step 75910\n",
      "ave_batch_reward 4.937088621987237 step 76020\n",
      "ave_batch_loss 9.315776189168295 step 76020\n",
      "ave_batch_reward 5.010903729332818 step 76130\n",
      "ave_batch_loss 9.854863484700521 step 76130\n",
      "ave_batch_reward 5.197844584782918 step 76240\n",
      "ave_batch_loss 10.364527066548666 step 76240\n",
      "ave_batch_reward 5.131709045834011 step 76350\n",
      "ave_batch_loss 9.939823309580484 step 76350\n",
      "ave_batch_reward 5.0646071963840065 step 76460\n",
      "ave_batch_loss 10.297867563035753 step 76460\n",
      "ave_batch_reward 5.259854899512397 step 76570\n",
      "ave_batch_loss 10.725326008266872 step 76570\n",
      "ave_batch_reward 5.191669093237983 step 76680\n",
      "ave_batch_loss 10.479854742685953 step 76680\n",
      "ave_batch_reward 5.318149248758952 step 76790\n",
      "ave_batch_loss 11.23034699757894 step 76790\n",
      "ave_batch_reward 5.158963574303521 step 76900\n",
      "ave_batch_loss 10.522744178771973 step 76900\n",
      "ave_batch_reward 5.036709785461426 step 77010\n",
      "ave_batch_loss 10.215548197428385 step 77010\n",
      "ave_batch_reward 5.106352594163683 step 77120\n",
      "ave_batch_loss 9.200578000810411 step 77120\n",
      "ave_batch_reward 5.07759788301256 step 77230\n",
      "ave_batch_loss 10.682355880737305 step 77230\n",
      "ave_batch_reward 5.106980800628662 step 77340\n",
      "ave_batch_loss 9.983697997199165 step 77340\n",
      "ave_batch_reward 5.093830320570204 step 77450\n",
      "ave_batch_loss 9.824940628475613 step 77450\n",
      "ave_batch_reward 5.165982246398926 step 77560\n",
      "ave_batch_loss 10.39587656656901 step 77560\n",
      "ave_batch_reward 5.304913971159193 step 77670\n",
      "ave_batch_loss 10.594213803609213 step 77670\n",
      "ave_batch_reward 5.326802306705051 step 77780\n",
      "ave_batch_loss 10.825844340854221 step 77780\n",
      "ave_batch_reward 5.272446473439534 step 77890\n",
      "ave_batch_loss 10.930225372314453 step 77890\n",
      "ave_batch_reward 5.160264121161567 step 78000\n",
      "ave_batch_loss 10.65129968855116 step 78000\n",
      "ave_batch_reward 4.8203526337941485 step 78110\n",
      "ave_batch_loss 8.609241167704264 step 78110\n",
      "ave_batch_reward 5.04392229186164 step 78220\n",
      "ave_batch_loss 9.67216804292467 step 78220\n",
      "ave_batch_reward 5.032659636603461 step 78330\n",
      "ave_batch_loss 9.737856441073948 step 78330\n",
      "ave_batch_reward 5.214506255255805 step 78440\n",
      "ave_batch_loss 10.66311370001899 step 78440\n",
      "ave_batch_reward 5.029968897501628 step 78550\n",
      "ave_batch_loss 9.700428167978922 step 78550\n",
      "ave_batch_reward 5.321996609369914 step 78660\n",
      "ave_batch_loss 10.435733795166016 step 78660\n",
      "ave_batch_reward 5.261936929490831 step 78770\n",
      "ave_batch_loss 10.595054414537218 step 78770\n",
      "ave_batch_reward 5.35589877764384 step 78880\n",
      "ave_batch_loss 10.566536585489908 step 78880\n",
      "ave_batch_reward 5.295144213570489 step 78990\n",
      "ave_batch_loss 10.730535401238335 step 78990\n",
      "ave_batch_reward 5.265034490161472 step 79100\n",
      "ave_batch_loss 10.510753313700357 step 79100\n",
      "ave_batch_reward 5.20058700773451 step 79210\n",
      "ave_batch_loss 10.526538954840767 step 79210\n",
      "ave_batch_reward 5.206698364681667 step 79320\n",
      "ave_batch_loss 10.365944756401909 step 79320\n",
      "ave_batch_reward 5.032871988084581 step 79430\n",
      "ave_batch_loss 9.566936280992296 step 79430\n",
      "ave_batch_reward 5.310051149792141 step 79540\n",
      "ave_batch_loss 9.41100788116455 step 79540\n",
      "ave_batch_reward 5.004603624343872 step 79650\n",
      "ave_batch_loss 9.790207068125406 step 79650\n",
      "ave_batch_reward 4.998966058095296 step 79760\n",
      "ave_batch_loss 9.327434910668266 step 79760\n",
      "ave_batch_reward 5.386136002010769 step 79870\n",
      "ave_batch_loss 10.378273752000597 step 79870\n",
      "ave_batch_reward 5.15426312552558 step 79980\n",
      "ave_batch_loss 10.928269068400065 step 79980\n",
      "ave_batch_reward 5.4525155491299095 step 80090\n",
      "ave_batch_loss 10.734340137905544 step 80090\n",
      "ave_batch_reward 5.093995518154568 step 80200\n",
      "ave_batch_loss 10.327956729465061 step 80200\n",
      "ave_batch_reward 5.141440682941013 step 80310\n",
      "ave_batch_loss 10.612775802612305 step 80310\n",
      "ave_batch_reward 5.288117567698161 step 80420\n",
      "ave_batch_loss 10.868513425191244 step 80420\n",
      "ave_batch_reward 5.128906197018093 step 80530\n",
      "ave_batch_loss 10.94553354051378 step 80530\n",
      "ave_batch_reward 5.3960466384887695 step 80640\n",
      "ave_batch_loss 11.120605680677626 step 80640\n",
      "ave_batch_reward 5.256850507524279 step 80750\n",
      "ave_batch_loss 10.823969523111979 step 80750\n",
      "ave_batch_reward 5.3023266262478295 step 80860\n",
      "ave_batch_loss 11.134651925828722 step 80860\n",
      "ave_batch_reward 5.343622340096368 step 80970\n",
      "ave_batch_loss 11.231866836547852 step 80970\n",
      "ave_batch_reward 5.109560410181682 step 81080\n",
      "ave_batch_loss 10.467093467712402 step 81080\n",
      "ave_batch_reward 5.214009337955051 step 81190\n",
      "ave_batch_loss 10.60459836324056 step 81190\n",
      "ave_batch_reward 5.140579700469971 step 81300\n",
      "ave_batch_loss 11.19592719607883 step 81300\n",
      "ave_batch_reward 5.378295527564155 step 81410\n",
      "ave_batch_loss 11.043146027459038 step 81410\n",
      "ave_batch_reward 5.226355658637153 step 81520\n",
      "ave_batch_loss 10.690575811598036 step 81520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 5.294468694263035 step 81630\n",
      "ave_batch_loss 11.053453551398384 step 81630\n",
      "ave_batch_reward 5.310504966311985 step 81740\n",
      "ave_batch_loss 10.643436008029514 step 81740\n",
      "ave_batch_reward 5.197653558519152 step 81850\n",
      "ave_batch_loss 10.487485567728678 step 81850\n",
      "ave_batch_reward 5.204704019758436 step 81960\n",
      "ave_batch_loss 10.172848383585611 step 81960\n",
      "ave_batch_reward 5.1916919814215765 step 82070\n",
      "ave_batch_loss 10.446391847398546 step 82070\n",
      "ave_batch_reward 5.258729298909505 step 82180\n",
      "ave_batch_loss 10.445213317871094 step 82180\n",
      "ave_batch_reward 5.175738493601481 step 82290\n",
      "ave_batch_loss 10.387900670369467 step 82290\n",
      "ave_batch_reward 5.215944078233507 step 82400\n",
      "ave_batch_loss 10.174155341254341 step 82400\n",
      "ave_batch_reward 5.108971277872722 step 82510\n",
      "ave_batch_loss 10.448970158894857 step 82510\n",
      "ave_batch_reward 5.010713524288601 step 82620\n",
      "ave_batch_loss 10.209090974595812 step 82620\n",
      "ave_batch_reward 5.145132011837429 step 82730\n",
      "ave_batch_loss 9.596218374040392 step 82730\n",
      "ave_batch_reward 5.076688978407118 step 82840\n",
      "ave_batch_loss 9.85835271411472 step 82840\n",
      "ave_batch_reward 5.238863706588745 step 82950\n",
      "ave_batch_loss 10.724106576707628 step 82950\n",
      "ave_batch_reward 4.84746159447564 step 83060\n",
      "ave_batch_loss 10.119718763563368 step 83060\n",
      "ave_batch_reward 5.137228488922119 step 83170\n",
      "ave_batch_loss 9.957062615288628 step 83170\n",
      "ave_batch_reward 5.125259876251221 step 83280\n",
      "ave_batch_loss 10.22718079884847 step 83280\n",
      "ave_batch_reward 5.113076554404365 step 83390\n",
      "ave_batch_loss 10.127587742275661 step 83390\n",
      "ave_batch_reward 5.1313189135657415 step 83500\n",
      "ave_batch_loss 10.23885366651747 step 83500\n",
      "ave_batch_reward 5.327460977766249 step 83610\n",
      "ave_batch_loss 10.062360127766928 step 83610\n",
      "ave_batch_reward 4.945862187279595 step 83720\n",
      "ave_batch_loss 9.293421268463135 step 83720\n",
      "ave_batch_reward 5.112069686253865 step 83830\n",
      "ave_batch_loss 9.910581217871773 step 83830\n",
      "ave_batch_reward 5.1377219094170465 step 83940\n",
      "ave_batch_loss 10.098095258076986 step 83940\n",
      "ave_batch_reward 5.158838589986165 step 84050\n",
      "ave_batch_loss 10.522982915242514 step 84050\n",
      "ave_batch_reward 5.278934849633111 step 84160\n",
      "ave_batch_loss 11.241213268703884 step 84160\n",
      "ave_batch_reward 5.195375442504883 step 84270\n",
      "ave_batch_loss 10.627765867445204 step 84270\n",
      "ave_batch_reward 5.163303454717 step 84380\n",
      "ave_batch_loss 11.093250698513454 step 84380\n",
      "ave_batch_reward 5.0887672901153564 step 84490\n",
      "ave_batch_loss 10.36475690205892 step 84490\n",
      "ave_batch_reward 4.953372001647949 step 84600\n",
      "ave_batch_loss 10.189798461066353 step 84600\n",
      "ave_batch_reward 5.405190467834473 step 84710\n",
      "ave_batch_loss 10.41301186879476 step 84710\n",
      "ave_batch_reward 5.116717709435357 step 84820\n",
      "ave_batch_loss 10.065082550048828 step 84820\n",
      "ave_batch_reward 5.292849169837104 step 84930\n",
      "ave_batch_loss 10.654626899295383 step 84930\n",
      "ave_batch_reward 5.1792043050130205 step 85040\n",
      "ave_batch_loss 10.35233211517334 step 85040\n",
      "ave_batch_reward 4.984410630332099 step 85150\n",
      "ave_batch_loss 9.38847573598226 step 85150\n",
      "ave_batch_reward 5.223800871107313 step 85260\n",
      "ave_batch_loss 10.19516372680664 step 85260\n",
      "ave_batch_reward 5.122306029001872 step 85370\n",
      "ave_batch_loss 10.893593576219347 step 85370\n",
      "ave_batch_reward 5.497701856825087 step 85480\n",
      "ave_batch_loss 10.411013921101889 step 85480\n",
      "ave_batch_reward 5.106380965974596 step 85590\n",
      "ave_batch_loss 10.428970336914062 step 85590\n",
      "ave_batch_reward 5.098251289791531 step 85700\n",
      "ave_batch_loss 10.538452572292751 step 85700\n",
      "ave_batch_reward 4.973709238900079 step 85810\n",
      "ave_batch_loss 9.476631376478407 step 85810\n",
      "ave_batch_reward 5.1647177537282305 step 85920\n",
      "ave_batch_loss 9.589389642079672 step 85920\n",
      "ave_batch_reward 5.199784543779161 step 86030\n",
      "ave_batch_loss 10.478149837917751 step 86030\n",
      "ave_batch_reward 5.0087163713243275 step 86140\n",
      "ave_batch_loss 10.222300953335232 step 86140\n",
      "ave_batch_reward 5.279166380564372 step 86250\n",
      "ave_batch_loss 9.726312743292915 step 86250\n",
      "ave_batch_reward 5.223687330881755 step 86360\n",
      "ave_batch_loss 10.595521291097006 step 86360\n",
      "ave_batch_reward 5.352589342329237 step 86470\n",
      "ave_batch_loss 10.75041749742296 step 86470\n",
      "ave_batch_reward 5.2685896555582685 step 86580\n",
      "ave_batch_loss 10.522546238369411 step 86580\n",
      "ave_batch_reward 5.168888303968641 step 86690\n",
      "ave_batch_loss 10.391822708977593 step 86690\n",
      "ave_batch_reward 5.2007622718811035 step 86800\n",
      "ave_batch_loss 10.223635567559135 step 86800\n",
      "ave_batch_reward 5.309011565314399 step 86910\n",
      "ave_batch_loss 10.70801427629259 step 86910\n",
      "ave_batch_reward 5.241111146079169 step 87020\n",
      "ave_batch_loss 10.821974224514431 step 87020\n",
      "ave_batch_reward 5.282995329962836 step 87130\n",
      "ave_batch_loss 11.037212901645237 step 87130\n",
      "ave_batch_reward 5.242354551951091 step 87240\n",
      "ave_batch_loss 10.032171885172525 step 87240\n",
      "ave_batch_reward 5.28945959938897 step 87350\n",
      "ave_batch_loss 10.750244246588814 step 87350\n",
      "ave_batch_reward 5.144719971550836 step 87460\n",
      "ave_batch_loss 9.810260984632704 step 87460\n",
      "ave_batch_reward 5.4241700702243385 step 87570\n",
      "ave_batch_loss 10.609662797715929 step 87570\n",
      "ave_batch_reward 5.28752522998386 step 87680\n",
      "ave_batch_loss 9.89353217018975 step 87680\n",
      "ave_batch_reward 5.184937900967068 step 87790\n",
      "ave_batch_loss 10.332199096679688 step 87790\n",
      "ave_batch_reward 4.942241085900201 step 87900\n",
      "ave_batch_loss 9.796245892842611 step 87900\n",
      "ave_batch_reward 4.983727667066786 step 88010\n",
      "ave_batch_loss 8.869480874803331 step 88010\n",
      "ave_batch_reward 5.198363012737698 step 88120\n",
      "ave_batch_loss 10.401990148756239 step 88120\n",
      "ave_batch_reward 5.275631374782986 step 88230\n",
      "ave_batch_loss 10.568694962395561 step 88230\n",
      "ave_batch_reward 5.197725137074788 step 88340\n",
      "ave_batch_loss 10.939192983839247 step 88340\n",
      "ave_batch_reward 5.361409081353082 step 88450\n",
      "ave_batch_loss 10.68459341261122 step 88450\n",
      "ave_batch_reward 5.180460876888699 step 88560\n",
      "ave_batch_loss 10.435775438944498 step 88560\n",
      "ave_batch_reward 5.107263988918728 step 88670\n",
      "ave_batch_loss 10.3513855404324 step 88670\n",
      "ave_batch_reward 5.266565216912164 step 88780\n",
      "ave_batch_loss 10.844097031487358 step 88780\n",
      "ave_batch_reward 5.2005599869622126 step 88890\n",
      "ave_batch_loss 10.547097735934788 step 88890\n",
      "ave_batch_reward 5.182326528761122 step 89000\n",
      "ave_batch_loss 10.044727749294704 step 89000\n",
      "ave_batch_reward 5.170008447435167 step 89110\n",
      "ave_batch_loss 10.341041564941406 step 89110\n",
      "ave_batch_reward 5.08598158094618 step 89220\n",
      "ave_batch_loss 8.896117475297716 step 89220\n",
      "ave_batch_reward 5.029451105329725 step 89330\n",
      "ave_batch_loss 9.862143834431967 step 89330\n",
      "ave_batch_reward 5.007489469316271 step 89440\n",
      "ave_batch_loss 9.598758697509766 step 89440\n",
      "ave_batch_reward 5.100026104185316 step 89550\n",
      "ave_batch_loss 9.6767242219713 step 89550\n",
      "ave_batch_reward 5.236894130706787 step 89660\n",
      "ave_batch_loss 10.64393785264757 step 89660\n",
      "ave_batch_reward 5.133793354034424 step 89770\n",
      "ave_batch_loss 10.65232711368137 step 89770\n",
      "ave_batch_reward 5.205047660403782 step 89880\n",
      "ave_batch_loss 10.619960890875923 step 89880\n",
      "ave_batch_reward 5.281410959031847 step 89990\n",
      "ave_batch_loss 10.707793447706434 step 89990\n",
      "ave_batch_reward 5.2794982062445746 step 90100\n",
      "ave_batch_loss 10.722698317633736 step 90100\n",
      "ave_batch_reward 5.063085900412665 step 90210\n",
      "ave_batch_loss 10.450225194295248 step 90210\n",
      "ave_batch_reward 5.109899097018772 step 90320\n",
      "ave_batch_loss 9.109695010715061 step 90320\n",
      "ave_batch_reward 4.987284104029338 step 90430\n",
      "ave_batch_loss 9.23345692952474 step 90430\n",
      "ave_batch_reward 5.248341878255208 step 90540\n",
      "ave_batch_loss 10.038775761922201 step 90540\n",
      "ave_batch_reward 5.246465682983398 step 90650\n",
      "ave_batch_loss 10.95754517449273 step 90650\n",
      "ave_batch_reward 5.219165272182888 step 90760\n",
      "ave_batch_loss 10.481894493103027 step 90760\n",
      "ave_batch_reward 5.344367133246528 step 90870\n",
      "ave_batch_loss 10.071489969889322 step 90870\n",
      "ave_batch_reward 5.200787650214301 step 90980\n",
      "ave_batch_loss 10.654825846354166 step 90980\n",
      "ave_batch_reward 5.149792035420735 step 91090\n",
      "ave_batch_loss 10.68219354417589 step 91090\n",
      "ave_batch_reward 4.988215234544542 step 91200\n",
      "ave_batch_loss 10.466920163896349 step 91200\n",
      "ave_batch_reward 4.990796513027615 step 91310\n",
      "ave_batch_loss 9.714657730526394 step 91310\n",
      "ave_batch_reward 4.941443920135498 step 91420\n",
      "ave_batch_loss 9.171300411224365 step 91420\n",
      "ave_batch_reward 5.171167055765788 step 91530\n",
      "ave_batch_loss 10.115831851959229 step 91530\n",
      "ave_batch_reward 5.281422985924615 step 91640\n",
      "ave_batch_loss 10.973850780063206 step 91640\n",
      "ave_batch_reward 5.146938959757487 step 91750\n",
      "ave_batch_loss 10.936571651034885 step 91750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ave_batch_reward 5.301935778723823 step 91860\n",
      "ave_batch_loss 10.830933888753256 step 91860\n",
      "ave_batch_reward 5.292596764034695 step 91970\n",
      "ave_batch_loss 11.030575964185926 step 91970\n",
      "ave_batch_reward 5.216263771057129 step 92080\n",
      "ave_batch_loss 10.467002126905653 step 92080\n",
      "ave_batch_reward 5.263163725535075 step 92190\n",
      "ave_batch_loss 10.864399062262642 step 92190\n",
      "ave_batch_reward 5.228837966918945 step 92300\n",
      "ave_batch_loss 10.853144751654732 step 92300\n",
      "ave_batch_reward 5.268167018890381 step 92410\n",
      "ave_batch_loss 11.212727228800455 step 92410\n",
      "ave_batch_reward 5.021034585105048 step 92520\n",
      "ave_batch_loss 10.067067305246988 step 92520\n",
      "ave_batch_reward 5.206266429689196 step 92630\n",
      "ave_batch_loss 10.495266278584799 step 92630\n",
      "ave_batch_reward 5.138407892651028 step 92740\n",
      "ave_batch_loss 10.678661028544107 step 92740\n",
      "ave_batch_reward 5.193681425518459 step 92850\n",
      "ave_batch_loss 11.118967692057291 step 92850\n",
      "ave_batch_reward 5.1619523366292315 step 92960\n",
      "ave_batch_loss 10.097411897447374 step 92960\n",
      "ave_batch_reward 4.852265146043566 step 93070\n",
      "ave_batch_loss 9.80770312415229 step 93070\n",
      "ave_batch_reward 5.099710146586101 step 93180\n",
      "ave_batch_loss 9.822599093119303 step 93180\n",
      "ave_batch_reward 5.124113692177667 step 93290\n",
      "ave_batch_loss 9.991974618699816 step 93290\n",
      "ave_batch_reward 5.2422553698221845 step 93400\n",
      "ave_batch_loss 10.711720042758518 step 93400\n",
      "ave_batch_reward 5.186904271443685 step 93510\n",
      "ave_batch_loss 10.873083114624023 step 93510\n",
      "ave_batch_reward 5.179649406009251 step 93620\n",
      "ave_batch_loss 10.177732467651367 step 93620\n",
      "ave_batch_reward 5.281024350060357 step 93730\n",
      "ave_batch_loss 10.786187277899849 step 93730\n",
      "ave_batch_reward 5.264223098754883 step 93840\n",
      "ave_batch_loss 10.872310956319174 step 93840\n",
      "ave_batch_reward 5.227134280734592 step 93950\n",
      "ave_batch_loss 10.683730125427246 step 93950\n",
      "ave_batch_reward 5.270254506005181 step 94060\n",
      "ave_batch_loss 9.739004082149929 step 94060\n",
      "ave_batch_reward 5.145771768358019 step 94170\n",
      "ave_batch_loss 10.139480749766031 step 94170\n",
      "ave_batch_reward 5.125859763887194 step 94280\n",
      "ave_batch_loss 10.346199035644531 step 94280\n",
      "ave_batch_reward 5.192408508724636 step 94390\n",
      "ave_batch_loss 10.42347494761149 step 94390\n",
      "ave_batch_reward 5.210449430677626 step 94500\n",
      "ave_batch_loss 10.546477211846245 step 94500\n",
      "ave_batch_reward 5.301932546827528 step 94610\n",
      "ave_batch_loss 10.27453507317437 step 94610\n",
      "ave_batch_reward 5.27704299820794 step 94720\n",
      "ave_batch_loss 10.325666215684679 step 94720\n",
      "ave_batch_reward 5.327822950151232 step 94830\n",
      "ave_batch_loss 10.692424774169922 step 94830\n",
      "ave_batch_reward 5.1623203489515515 step 94940\n",
      "ave_batch_loss 10.301141738891602 step 94940\n",
      "ave_batch_reward 5.220036109288533 step 95050\n",
      "ave_batch_loss 10.720580418904623 step 95050\n",
      "ave_batch_reward 5.026661396026611 step 95160\n",
      "ave_batch_loss 10.030099127027723 step 95160\n",
      "ave_batch_reward 5.252279652489556 step 95270\n",
      "ave_batch_loss 10.298395474751791 step 95270\n",
      "ave_batch_reward 5.247851795620388 step 95380\n",
      "ave_batch_loss 10.301386727227104 step 95380\n",
      "ave_batch_reward 5.118248250749376 step 95490\n",
      "ave_batch_loss 10.866206910875109 step 95490\n",
      "ave_batch_reward 5.59980387157864 step 95600\n",
      "ave_batch_loss 10.787612385219997 step 95600\n",
      "ave_batch_reward 5.163931475745307 step 95710\n",
      "ave_batch_loss 10.52506595187717 step 95710\n",
      "ave_batch_reward 5.512165228525798 step 95820\n",
      "ave_batch_loss 11.11463843451606 step 95820\n",
      "ave_batch_reward 5.184179491466946 step 95930\n",
      "ave_batch_loss 11.436175770229763 step 95930\n",
      "ave_batch_reward 5.144647439320882 step 96040\n",
      "ave_batch_loss 10.081375651889378 step 96040\n",
      "ave_batch_reward 5.036989344490899 step 96150\n",
      "ave_batch_loss 9.547603183322483 step 96150\n",
      "ave_batch_reward 5.300917572445339 step 96260\n",
      "ave_batch_loss 9.136022514767117 step 96260\n",
      "ave_batch_reward 5.172155062357585 step 96370\n",
      "ave_batch_loss 10.649266560872396 step 96370\n",
      "ave_batch_reward 5.203261269463433 step 96480\n",
      "ave_batch_loss 10.525018903944227 step 96480\n",
      "ave_batch_reward 5.309455341762966 step 96590\n",
      "ave_batch_loss 10.907987382676867 step 96590\n",
      "ave_batch_reward 5.274382432301839 step 96700\n",
      "ave_batch_loss 10.940668741861979 step 96700\n",
      "ave_batch_reward 5.4693582852681475 step 96810\n",
      "ave_batch_loss 10.798074086507162 step 96810\n",
      "ave_batch_reward 5.101797925101386 step 96920\n",
      "ave_batch_loss 10.515171686808268 step 96920\n",
      "ave_batch_reward 5.447841750250922 step 97030\n",
      "ave_batch_loss 11.134664323594835 step 97030\n",
      "ave_batch_reward 5.227739625506931 step 97140\n",
      "ave_batch_loss 10.71133698357476 step 97140\n",
      "ave_batch_reward 5.119071112738715 step 97250\n",
      "ave_batch_loss 10.678314844767252 step 97250\n",
      "ave_batch_reward 5.117080264621311 step 97360\n",
      "ave_batch_loss 10.197027206420898 step 97360\n",
      "ave_batch_reward 5.078286912706163 step 97470\n",
      "ave_batch_loss 10.579412354363335 step 97470\n",
      "ave_batch_reward 5.262175665961371 step 97580\n",
      "ave_batch_loss 9.880731476677788 step 97580\n",
      "ave_batch_reward 5.233803060319689 step 97690\n",
      "ave_batch_loss 10.676635212368435 step 97690\n",
      "ave_batch_reward 5.316464742024739 step 97800\n",
      "ave_batch_loss 10.690876536899143 step 97800\n",
      "ave_batch_reward 5.106261041429308 step 97910\n",
      "ave_batch_loss 10.193738831414116 step 97910\n",
      "ave_batch_reward 5.236150476667616 step 98020\n",
      "ave_batch_loss 11.01217630174425 step 98020\n",
      "ave_batch_reward 5.225958479775323 step 98130\n",
      "ave_batch_loss 9.91768635643853 step 98130\n",
      "ave_batch_reward 5.0607030391693115 step 98240\n",
      "ave_batch_loss 10.810578982035318 step 98240\n",
      "ave_batch_reward 5.36248583263821 step 98350\n",
      "ave_batch_loss 10.971597989400228 step 98350\n",
      "ave_batch_reward 5.1041361755794945 step 98460\n",
      "ave_batch_loss 10.9944519466824 step 98460\n",
      "ave_batch_reward 5.3532598283555775 step 98570\n",
      "ave_batch_loss 10.901804712083605 step 98570\n",
      "ave_batch_reward 5.008285125096639 step 98680\n",
      "ave_batch_loss 10.2672971089681 step 98680\n",
      "ave_batch_reward 5.094728284411961 step 98790\n",
      "ave_batch_loss 9.83014350467258 step 98790\n",
      "ave_batch_reward 5.254120508829753 step 98900\n",
      "ave_batch_loss 10.024568875630697 step 98900\n",
      "ave_batch_reward 5.080644051233928 step 99010\n",
      "ave_batch_loss 9.796827846103245 step 99010\n",
      "ave_batch_reward 5.374800735049778 step 99120\n",
      "ave_batch_loss 10.716091791788736 step 99120\n",
      "ave_batch_reward 5.143933084275988 step 99230\n",
      "ave_batch_loss 10.103921678331163 step 99230\n",
      "ave_batch_reward 5.142852889166938 step 99340\n",
      "ave_batch_loss 10.302452405293783 step 99340\n",
      "ave_batch_reward 5.170258813434177 step 99450\n",
      "ave_batch_loss 9.930022027757433 step 99450\n",
      "ave_batch_reward 5.15187062157525 step 99560\n",
      "ave_batch_loss 10.209431012471518 step 99560\n",
      "ave_batch_reward 5.039477613237169 step 99670\n",
      "ave_batch_loss 9.86026758617825 step 99670\n",
      "ave_batch_reward 5.4380873044331866 step 99780\n",
      "ave_batch_loss 10.57602988349067 step 99780\n",
      "ave_batch_reward 5.149151775572035 step 99890\n",
      "ave_batch_loss 10.634781943427193 step 99890\n",
      "ave_batch_reward 5.2956492106119795 step 100000\n",
      "ave_batch_loss 11.406852298312717 step 100000\n"
     ]
    }
   ],
   "source": [
    "#device = \"cuda\"\n",
    "device = \"cpu\"\n",
    "\n",
    "#create multiple environments for multiprocessing\n",
    "make_env = lambda: SchedulerEnv()\n",
    "envs = [make_env() for _ in range(num_envs)]\n",
    "\n",
    "#start writing to tensorboard\n",
    "writer = SummaryWriter(comment=\"Scheduler\")\n",
    "\n",
    "#initialise model, agent and run through episodes to get experience\n",
    "model = Model(envs[0].observation_space.shape, envs[0].action_space.n).to(device)\n",
    "agent = ptan.agent.PolicyAgent(lambda x: model(x)[0], apply_softmax=True, device=device)\n",
    "exp_source = ptan.experience.ExperienceSourceFirstLast(envs, agent, gamma=gamma, steps_count=reward_steps)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, eps=1e-3)\n",
    "\n",
    "#create list to capture batches\n",
    "batch = []\n",
    "\n",
    "#create lists to be used to record values for tracking averages\n",
    "reward_stack = []\n",
    "loss_stack = []\n",
    "\n",
    "#work through each experience source to capture state, actions etc\n",
    "for step_idx, exp in enumerate(exp_source):\n",
    "    batch.append(exp)\n",
    "\n",
    "    if len(batch) < batch_size:\n",
    "        continue\n",
    "\n",
    "    states, actions, rewards = unpack_batch(batch, model, device=device)\n",
    "    batch.clear()\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # using the network to give actions and state_value\n",
    "    actor_val, critic_val = model(states)\n",
    "    # [CRITIC] calculate the loss between value_state (just predicted now) and reward from the batch\n",
    "    critic_loss = F.mse_loss(critic_val.squeeze(-1), rewards)\n",
    "\n",
    "    # Runs the log_softmax against actor output (just predicted now)\n",
    "    log_prob = F.log_softmax(actor_val, dim=1)\n",
    "    # Advantage equals reward from the batch (size:[batch_size]) minus the value_state (just predicted now)\n",
    "    advantage = rewards - critic_val.detach()\n",
    "\n",
    "    # multiples the advantage at each step by the log probability of the chosen action for that step\n",
    "    log_prob_actions = advantage * log_prob[range(batch_size), actions]\n",
    "    # calculate the policy gradient adjustment to make (negated to move toward policy improvement)\n",
    "    actor_loss = -log_prob_actions.mean()\n",
    "\n",
    "    # perform softmax on action estimates (from ACTOR) (just predicted now)\n",
    "    prob_val = F.softmax(actor_val, dim=1)\n",
    "    # calculating the action entropy \n",
    "    entropy_loss = 0.01 * (prob_val * log_prob).sum(dim=1).mean()\n",
    "\n",
    "    # calculate policy gradients only\n",
    "\n",
    "    # [ACTOR] backpropogate\n",
    "    actor_loss.backward(retain_graph=True)\n",
    "\n",
    "    # apply entropy and value gradients\n",
    "    # [CRITIC] backpropagate and apply entropy\n",
    "    loss = entropy_loss + critic_loss\n",
    "    loss.backward()\n",
    "\n",
    "    optimizer.step()\n",
    "\n",
    "    #send average loss and rewards to tensorboard\n",
    "    if len(reward_stack) > 0 and step_idx % 10 == 0:\n",
    "        #print(step_idx)\n",
    "        avg_rewards = np.mean(reward_stack)\n",
    "        avg_loss = np.mean(loss_stack)\n",
    "        writer.add_scalar('ave_batch_reward', avg_rewards, step_idx)\n",
    "        writer.add_scalar('ave_batch_loss', avg_loss, step_idx)\n",
    "        print('ave_batch_reward', avg_rewards, 'step', step_idx)\n",
    "        print('ave_batch_loss', avg_loss, 'step', step_idx)\n",
    "        reward_stack.clear()\n",
    "        loss_stack.clear()\n",
    "    else:\n",
    "        reward_stack.append(torch.mean(rewards).item())\n",
    "        loss_stack.append(torch.mean(critic_loss).item())\n",
    "        \n",
    "    if step_idx > 100000:\n",
    "        break\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
